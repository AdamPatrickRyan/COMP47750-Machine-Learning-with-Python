{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da1a3d8",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "---\n",
    "\n",
    "Author: Adam Ryan\n",
    "\n",
    "Created Date: 2021-09-14\n",
    "\n",
    "Date Last Modified: 2021-10-24\n",
    "\n",
    "Description: A solution to Assignment 1 regarding the implementation of MyGaussianNB which implements Gaussian Naive Bayes.\n",
    "\n",
    "---\n",
    "\n",
    "## Task Description\n",
    "\n",
    "### Objective\n",
    "The objective of this assignment is to implement a Gaussian Naive Bayes classifier in the scikit-learn framework. A notebook (MajorityClassClf) is provided with a simple example of a classifier that works with scikit-learn.\n",
    "\n",
    "Note: The code developed in this assignment will be extended in the second assignment to allow for missing values. \n",
    "\n",
    "### Requirements\n",
    "The notebook MajorityClassClf contains some basic code to help you get started. \n",
    "Provide a python class MyGaussianNB that implements Gaussian Naive Bayes. The conditional probabilities should be calculated as follows:\n",
    "        \n",
    "       \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{P}(x_i | y) = \\frac{1}{\\sqrt{2 \\pi (\\sigma_{y_i})^2}} e^{-\\frac{(x_i - \\mu_y)^2}{2(\\sigma_{y_i})^2}} = \\frac{1}{\\sqrt{2 \\pi (\\sigma_{y_i})^2}} \\text{exp}({-\\frac{(x_i - \\mu_y)^2}{2(\\sigma_{y_i})^2}})\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "where 𝜇y is the mean for variable i for class y and 𝜎y is the corresponding standard deviation. Thereafter the classification should use the NB formulae presented in the lectures. Alternatives that use addition of conditional probabilities or logs should not be used. \n",
    "    \n",
    "The API specification for sklearn classifiers is here: https://scikit-learn.org/stable/developers/develop.html \n",
    "You should implement the ‘fit’ and ‘predict’ methods, there is no need to implement ‘predict_proba’. \n",
    "Prior probabilities should be calculated from the training data. With this, there will be no need to pass parameters when instances are created. \n",
    "\n",
    "Test the performance of your implementation against the GaussianNB implementation in scikit-learn. You should use a range of datasets for this testing. Possible test sets used in lectures are penguins,  diabetes and glassV2. \n",
    "\n",
    "### Submission\n",
    "This is an individual (not group) project. Submission is through the Brightspace page. Your submission should comprise your notebook and the second dataset that you use. Clear all outputs in the notebook before saving for submission. You can use markdown cells in the notebook to report your findings and conclusions. \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Solution\n",
    "\n",
    "### Explanation\n",
    "\n",
    "1. A function is created which creates models: SK Naive Bayes and My Naive Bayes.\n",
    "2. The My Naive Bayes function is defined. \n",
    "    1. Fit does validation and prepares the class stats for predict.\n",
    "    2. Predict validates it has been fitted. It goes through each row in the test data, and for each row for every class it goes through each column and gets the probability using the Gaussian NB PDF and then derives total row probability for that class. I do not normalise the probabilities across n-many classes as the only piece which matters is the max class. I add this to an array and return it. Validation is done against std.Dev=0 by setting it to the square root of the minimum float in this instance.\n",
    "3. Some functions are defined to create models (MyNaiveBayes and SKLearnBaye) and analyse them.\n",
    "4. Functions are designed to read in all datasets and test my implementation and the default implementation and validate they produce equal classification reports.\n",
    "5. We observe equality in the classification results we are obtaining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f7b8cc",
   "metadata": {},
   "source": [
    "#### Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb0bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####--------------------------------------\n",
    "#00.Import Modules\n",
    "####--------------------------------------\n",
    "\n",
    "\n",
    "######---------BEGIN\n",
    "#      SUPPRESS DEPRECIATION WARNINGS: Applicable to datetime_is_numeric=True\n",
    "######--------END\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "######---------BEGIN\n",
    "#      ML\n",
    "######--------END\n",
    "\n",
    "#import nltk as nl\n",
    "import sklearn as sk\n",
    "#import xgboost as xg\n",
    "#import pymc3 as pymc\n",
    "#import sympy as sym\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "#from sklearn.tree import export_graphviz\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "######---------BEGIN\n",
    "#      SQL\n",
    "######--------END\n",
    "\n",
    "\n",
    "\n",
    "######---------BEGIN\n",
    "#     GENERAL\n",
    "######--------END\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "\n",
    "######---------BEGIN\n",
    "#     DATA VIS\n",
    "######--------END\n",
    "\n",
    "import matplotlib as mp\n",
    "#from bokeh import *\n",
    "#from dash import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88819f56",
   "metadata": {},
   "source": [
    "# My Gaussian Naive Bayes Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "919b38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNB(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"A class to capture My Gaussian Naive Bayes\n",
    "    \n",
    "    Input: \n",
    "    BaseEstimator\n",
    "    ClassifierMixin\n",
    "    \n",
    "    Output:\n",
    "    An item of the MGNB class.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialise\n",
    "        \n",
    "        Fit function populates each Attribute.\n",
    "        \n",
    "        Important Note: I am not defining the attributes here, they're merely being documented.\n",
    "        This is done so that the is_fitted method works to validate that the instance has been fitted, and raises an error if not\"\"\"\n",
    "    \n",
    "        #Initial data\n",
    "        ##self.X_=None\n",
    "        ##self.y_=None\n",
    "        \n",
    "        #Unique Class Labels\n",
    "        #self.classes_=None\n",
    "        \n",
    "        #Statistics for each class - Mean, std, Perc\n",
    "        ##self.summary_stats_=dict()\n",
    "        \n",
    "        #Matrix for each Class\n",
    "        ##self.class_dict_=dict()\n",
    "        \n",
    "        #Predict Variables\n",
    "        ##self.X_test_=None\n",
    "        ##self.y_test_=None\n",
    "        \n",
    "        #Cont Table\n",
    "        ##self.cont_dict_=dict()\n",
    "        ##self.raw_dict_=dict()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def fit(self, Xt, yt):\n",
    "        \"\"\"A function to fit the data.\n",
    "        \n",
    "        ---\n",
    "        First it validates the checks \n",
    "        -> Is it a Dataframe, list, or Numpy Array?\n",
    "        -> Is it non-empty?\n",
    "        -> Are they the same size?\n",
    "        -> Is it numeric only?\n",
    "        \n",
    "        Second:\n",
    "        It sets the X and y values\n",
    "        \n",
    "        Third:\n",
    "        It gets the unique clases.\n",
    "        \n",
    "        Fourth:\n",
    "        It gets the summary stats which are needed for the probability calculation for each class.\n",
    "        ---\n",
    "        \n",
    "        I work solely with numpy arrays. \n",
    "        In hindsight it would have been much easier to use Pandas dataframes but I believe numpy is meant to be faster as it's based in C.\n",
    "        \n",
    "        Input:\n",
    "        Xt: List - X values\n",
    "        yt: List - y values\n",
    "        \n",
    "        Output:\n",
    "        ???\"\"\"\n",
    "        \n",
    "        #Validate the type of the inputs -> Note I wrote this before seeing SKLearn recommendation\n",
    "        Xt=self.__validate_input_type(Xt)\n",
    "        yt=self.__validate_input_type(yt)  \n",
    "        \n",
    "        #Validate the training set contains numbers\n",
    "        if not self.__validate_numeric(Xt):\n",
    "            raise ValueError(\"All inputs in the training set should be numeric\")\n",
    "        \n",
    "        if not self.__validate_length(X=Xt,y=yt):\n",
    "            raise ValueError(\"Arrays are of different length\")\n",
    "            \n",
    "        if len(yt)<1:\n",
    "            raise ValueError(\"Empty arrays are not alloweed\")\n",
    "            \n",
    "\n",
    "        #https://scikit-learn.org/stable/developers/develop.html Recommends using these two instead of the above.\n",
    "        Xt, yt = check_X_y(Xt, yt)\n",
    "        \n",
    "        #Post Validation\n",
    "        self.X_ = Xt\n",
    "        \n",
    "        #Store class labels as strings\n",
    "        self.y_ = np.array(yt, dtype=str)\n",
    "        \n",
    "        #Set the list of classes\n",
    "        self.classes_ = unique_labels(self.y_)\n",
    "        \n",
    "        #Set the class dictionary\n",
    "        self.__class_dict()\n",
    "        \n",
    "        #Get the stats for each Class and set it\n",
    "        self.__set_class_stats()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"A function to predict a test set.\n",
    "        \n",
    "        Input: \n",
    "        X_test: List/array/dataframe\n",
    "        \n",
    "        Output:\n",
    "        ???\"\"\"\n",
    "        \n",
    "        X_test=self.__validate_input_type(X_test)\n",
    "        \n",
    "        #Validate the test set contains numbers\n",
    "        if not self.__validate_numeric(X_test):\n",
    "            raise ValueError(\"All inputs in the training set should be numeric\")\n",
    "            \n",
    "        #Validate the test set has same column count as training\n",
    "        if not self.__validate_column_count(X_train=self.X_,X_test=X_test):\n",
    "            raise ValueError(\"The test set should have the same column count as the training set\")\n",
    "            \n",
    "        X_test = check_array(X_test, accept_sparse=True)\n",
    "    \n",
    "        #Check the model has been fitted -> Returns error if not.\n",
    "        check_is_fitted(self, attributes=['X_','y_','classes_','class_dict_','summary_stats_'],msg='is_fitted_')\n",
    "        \n",
    "        #Passed validation\n",
    "        self.X_test_=X_test\n",
    "        \n",
    "        #BEGIN WITH PREDICTING\n",
    "        y_pred=[]\n",
    "        \n",
    "        column_count=len(X_test[0])\n",
    "        \n",
    "        class_summary_stats=self.get_class_stats()\n",
    "        \n",
    "        row_class_dict=dict()\n",
    "        raw_contingency_dictionary=dict()\n",
    "        \n",
    "        #For each row in the test data, take the row\n",
    "        for row_index in range(len(X_test)):\n",
    "            \n",
    "            #get a single row\n",
    "            row_value=X_test[row_index]\n",
    "            row_class_dict[row_index]=dict()\n",
    "            raw_contingency_dictionary[row_index]=dict()\n",
    "            \n",
    "            #For that row, get the probability values for every class\n",
    "            for class_label in self.get_classes():\n",
    "                \n",
    "                #Empty array to calculate probability for that row\n",
    "                row_list=[]\n",
    "                \n",
    "                #class Stats\n",
    "                class_mean=class_summary_stats[class_label]['Mean']\n",
    "                class_std=class_summary_stats[class_label]['Standard Deviation']\n",
    "                class_percent=class_summary_stats[class_label]['Percent']\n",
    "                \n",
    "                #Go through column for that row and add in probability:\n",
    "                for column_index in range(column_count):\n",
    "                    row_list+=[self.__calculate_gaussian_probability(x=row_value[column_index]\n",
    "                                                                     ,mean=class_mean[column_index]\n",
    "                                                                     , std_dev=class_std[column_index])]\n",
    "                    \n",
    "\n",
    "                \n",
    "                #This stores the probability values calculated for each row for each class to refer back to later\n",
    "                raw_contingency_dictionary[row_index][class_label]= np.array(row_list)\n",
    "                \n",
    "                #This just stores the probability for that class\n",
    "                row_class_dict[row_index][class_label]= np.prod(np.array(row_list)) * class_percent\n",
    "                \n",
    "            \n",
    "            #Probabilities calculated for each class - for that row index get the class:\n",
    "            class_for_row=max(row_class_dict[row_index], key=row_class_dict[row_index].get)\n",
    "            \n",
    "            y_pred+=[class_for_row]\n",
    "            \n",
    "        y_pred=np.array(y_pred)   \n",
    "        self.cont_dict_=row_class_dict\n",
    "        self.raw_dict_=raw_contingency_dictionary\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict_proba(self, Xtes):\n",
    "        \"\"\"A function to predict the probability\"\"\"\n",
    "        pass\n",
    "    # We should really be implementing predict_proba as well.\n",
    "    \n",
    "    \n",
    "    \n",
    "    #A function to get a dictionary for the class\n",
    "    def __class_dict(self):\n",
    "        \"\"\"A function to make a dictionary such that each class is held in the dictionary and all rows of data are put against that class.\n",
    "        \n",
    "        Input: \n",
    "        X -> n-dimensional Array\n",
    "        y -> Single-dimensional array\n",
    "        \n",
    "        Output:\n",
    "        Dictionary -> {Class1:[Row_{1,1},Row_{1,2},...Row_{1,K}]\n",
    "                        ,Class2:[Row_{2,1},...Row_{2,m}]\n",
    "                        ,...\n",
    "                        ,ClassN:[R_{N,1},...R_{N,x}]}\n",
    "        \n",
    "        \"\"\"\n",
    "        class_dict=dict()\n",
    "        \n",
    "        X=self.X_\n",
    "        y=self.y_\n",
    "        \n",
    "        #Each row in the matrix\n",
    "        for row_index in range(len(y)):\n",
    "            \n",
    "            class_value=y[row_index]\n",
    "            \n",
    "            if class_value not in class_dict:\n",
    "                class_dict[class_value]=[np.array(X[row_index])]\n",
    "                \n",
    "            else:\n",
    "                class_dict[class_value]+=[np.array(X[row_index])]\n",
    "                \n",
    "        \n",
    "                \n",
    "        for class_value in self.classes_:\n",
    "            class_dict[class_value]=np.array(class_dict[class_value])\n",
    "            \n",
    "        self.class_dict_=class_dict\n",
    "        \n",
    "        return\n",
    "            \n",
    "    #A function to get the statistics for each class\n",
    "    def __set_class_stats(self):\n",
    "        \"\"\"For each class, get the summary statistics, mainly:\n",
    "        -> Mean, standard dev, percentage of presence\n",
    "        \n",
    "        I.e.:\n",
    "        class1:[Mean_1,std_1,Percent of Total_1]\n",
    "        ,class2:[Mean_2,std_2,Percent of Total_2]\n",
    "        ,...,\n",
    "        classN:[Mean_N,std_N,Percent of Total_N]\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        stat_dict=dict()\n",
    "        \n",
    "        for pred_class in self.classes_:\n",
    "            \n",
    "            #Matrix of classes\n",
    "            class_matrix=self.class_dict_[pred_class]\n",
    "            \n",
    "            #Class:\n",
    "            stat_dict[pred_class]={\n",
    "                                'Mean':self.__get_column_means(class_matrix)\n",
    "                                ,'Standard Deviation':self.__get_column_std_dev(class_matrix)\n",
    "                                ,'Percent':(self.__get_row_count(class_matrix) / len((self.y_)))\n",
    "                                }\n",
    "    \n",
    "        \n",
    "        self.summary_stats_=stat_dict\n",
    "        \n",
    "        return\n",
    "        \n",
    "    \n",
    "    #Getter\n",
    "    def get_x(self):\n",
    "        return self.X_\n",
    "    \n",
    "    #Getter\n",
    "    def get_y(self):\n",
    "        return self.y_\n",
    "    \n",
    "    #Getter\n",
    "    def get_classes(self):\n",
    "        return self.classes_\n",
    "    \n",
    "    #Getter\n",
    "    def get_class_dict(self):\n",
    "        return self.class_dict_\n",
    "    \n",
    "    #Getter\n",
    "    def get_class_stats(self):\n",
    "        return self.summary_stats_\n",
    "    \n",
    "\n",
    "    #Getter\n",
    "    def get_raw_dict(self):\n",
    "        return self.raw_dict_\n",
    "    \n",
    "    def get_cont_dict(self):\n",
    "        return cont_dict_\n",
    "                \n",
    "        \n",
    "    #MEANS\n",
    "    @staticmethod   \n",
    "    def __get_column_means(X):\n",
    "        \"\"\"Get the column mean of an Array x\"\"\"\n",
    "        return X.mean(axis=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def __get_row_means(X):\n",
    "        \"\"\"Get the row mean of an Array x\"\"\"\n",
    "        return X.mean(axis=1)\n",
    "    \n",
    "    \n",
    "    #Standard Deviations\n",
    "    @staticmethod\n",
    "    def __get_column_std_dev(X):\n",
    "        \"\"\"Get the column std dev of an Array x\"\"\"\n",
    "        return X.std(axis=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def __get_row_std_dev(X):\n",
    "        \"\"\"Get the row std dev of an Array x\"\"\"\n",
    "        return X.std(axis=1)\n",
    "    \n",
    "    #Counts\n",
    "    @staticmethod   \n",
    "    def __get_column_count(X):\n",
    "        \"\"\"Get the column Count of an Array x\"\"\"\n",
    "        return len(X.T)\n",
    "    \n",
    "    @staticmethod   \n",
    "    def __get_row_count(X):\n",
    "        \"\"\"Get the row count of an Array x\"\"\"\n",
    "        return len(X)\n",
    "    \n",
    "    \n",
    "    #Probability Function\n",
    "    @staticmethod\n",
    "    def __calculate_gaussian_probability(x, mean, std_dev):\n",
    "        \"\"\"A function to implement the pdf for a gaussian\"\"\"\n",
    "        \n",
    "        if std_dev==0:\n",
    "            #This way squaring it will be well defined\n",
    "            std_dev=sys.float_info.min**(1/2)\n",
    "            \n",
    "        first_term= (1 / (np.sqrt(2 * np.pi) * std_dev))\n",
    "        second_term= (np.exp(-((x-mean)**2 / (2 * (std_dev**2) ))))\n",
    "        gaussian_pdf =  first_term*second_term\n",
    "        \n",
    "        return  gaussian_pdf\n",
    "        \n",
    "    \n",
    "    #Validation\n",
    "    @staticmethod\n",
    "    def __validate_numeric(X):\n",
    "        \"\"\"A function to check that X is a numeric array\"\"\"\n",
    "        return X.dtype.kind in ('b','u','i','f','c')\n",
    "    \n",
    "    #Validation\n",
    "    @staticmethod\n",
    "    def __validate_length(X,y):\n",
    "        \"\"\"A function to check that X and y are equal length\"\"\"\n",
    "        return len(X)==len(y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def __validate_column_count(X_train,X_test):\n",
    "        \"\"\"A function to check that X_train and X_test are equal length\"\"\"\n",
    "        return len(X_train[0])==len(X_test[0])\n",
    "    \n",
    "    @staticmethod\n",
    "    def __validate_input_type(X):\n",
    "        \"\"\"Validate the type of X\"\"\"\n",
    "        if not (isinstance(X,list) or isinstance(X, np.ndarray)):\n",
    "            if isinstance(X,pd.DataFrame):\n",
    "                X=X.to_numpy()\n",
    "                return X\n",
    "\n",
    "            else:\n",
    "                raise TypeError(\"Input must be a list, numpy array, or dataframe\")\n",
    "                \n",
    "        return np.array(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71b264e",
   "metadata": {},
   "source": [
    "# A function to analyse Models and wrap model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58535f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_index_array(l1,l2):\n",
    "    \n",
    "    bool_array=[]\n",
    "    \n",
    "    for pos in range(len(l1)):\n",
    "        bool_array+=[l1[pos]==l2[pos]]\n",
    "        \n",
    "    return bool_array\n",
    "\n",
    "\n",
    "def model_metrics(testActualVal, predictions,verbose=True):\n",
    "    \"\"\"A function to get Metrics for a Model\n",
    "    \n",
    "    Note: This is a function I wrote for the Research Practicum: \n",
    "    https://github.com/Team10UCD/Frontend/blob/cc12998790b7207a859d5089e10f085a65586294/flask/Data_Analytics/Model_Analytics/Route102_sample/02_local_ModelExplorationAndFeatureSelection_Route102.ipynb\"\"\"\n",
    "    \n",
    "    try:\n",
    "        accuracy=metrics.accuracy_score(testActualVal, predictions)\n",
    "    except:\n",
    "        accuracy=None\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        confusion_matrix=metrics.confusion_matrix(testActualVal, predictions)\n",
    "    except:\n",
    "        confusion_matrix=None\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        classification_rep=metrics.classification_report(testActualVal, predictions,output_dict=True)\n",
    "    except:\n",
    "        classification_rep=None\n",
    "        pass\n",
    "    \n",
    "    if verbose:\n",
    "        \n",
    "        try:\n",
    "            print(\"----DETAIL----\")\n",
    "            print(\"\\n\\nAccuracy: \\n\")\n",
    "            display(accuracy)\n",
    "            print(\"\\n\\nConfusion matrix: \\n\")\n",
    "            display(confusion_matrix)\n",
    "            print(\"\\n\\nClassification report:\\n \")\n",
    "            display(classification_rep)\n",
    "            \n",
    "        except:\n",
    "            print(\"----DETAIL----\")\n",
    "            print(\"\\n\\nAccuracy: \\n\", accuracy)\n",
    "            print(\"\\n\\nConfusion matrix: \\n\", confusion_matrix)\n",
    "            print(\"\\n\\nClassification report:\\n \", classification_rep)\n",
    "            \n",
    "    \n",
    "    result_dict={}\n",
    "    result_dict['Accuracy']=accuracy\n",
    "    result_dict['Confusion']=confusion_matrix\n",
    "    result_dict['ClassificationRep']=classification_rep\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def create_model(X,y,scaler='Standard',random_state=14395076,plot_comp=True,assess=True,test_size=0.33, verbose=True,mod_type=''):\n",
    "    \"\"\"A wrapper to call the create model function\"\"\"\n",
    "\n",
    "    \n",
    "    if mod_type=='My Naive Bayes':\n",
    "        mod_result=create_my_naive_bayes(X=X\n",
    "                                         ,y=y\n",
    "                                         ,plot_comp=plot_comp\n",
    "                                         ,scaler=scaler\n",
    "                                         ,assess=assess\n",
    "                                         ,random_state=random_state\n",
    "                                         , verbose=verbose\n",
    "                                        ,test_size=test_size)\n",
    "        return mod_result\n",
    "\n",
    "    \n",
    "    \n",
    "    elif mod_type==\"SK Naive Bayes\":\n",
    "        mod_result=create_sk_naive_bayes(X=X\n",
    "                                         ,y=y\n",
    "                                         ,plot_comp=plot_comp\n",
    "                                         ,random_state=random_state\n",
    "                                         ,scaler=scaler\n",
    "                                         ,assess=assess\n",
    "                                         , verbose=verbose\n",
    "                                        ,test_size=test_size)\n",
    "    \n",
    "        return mod_result\n",
    "    \n",
    "    else:\n",
    "        print(\"Sorry, I've not built that yet.\")\n",
    "        raise ValueError(\"Must be My Naive Bayes or SK Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040095e6",
   "metadata": {},
   "source": [
    "# Create a model using the default SKLearn estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fe28aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sk_naive_bayes(X,y,plot_comp,scaler='Standard', random_state=14395076,assess=True, test_size=0.33,verbose=True):\n",
    "    \"\"\"Create a model using SK's Naive Bayes.\"\"\"\n",
    "    \n",
    "    \n",
    "    print(\"\"\"\n",
    "-\n",
    "SKLEARN NAIVE BAYES:\n",
    "-\n",
    "          \n",
    "          \"\"\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X \n",
    "                                                        ,y\n",
    "                                                        ,random_state=random_state\n",
    "                                                        ,test_size=test_size)\n",
    "    \n",
    "    if scaler=='Standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler=='MinMax':    \n",
    "        scaler = MinMaxScaler()\n",
    "    else:\n",
    "        raise ValueError(\"Need to implemenet your scaler - Choose Standard or MinMax\")\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    start=time.perf_counter()\n",
    "    \n",
    "    #Create the DT Regression\n",
    "    model = GaussianNB()\n",
    "\n",
    "    #Fit the data\n",
    "    model.fit(X_train,y_train)\n",
    "   \n",
    "    \n",
    "    #Check the predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    end=time.perf_counter()\n",
    "    \n",
    "    print(\"Total Time to Classify: {}\".format(end-start))\n",
    "    \n",
    "    \n",
    "    #Results\n",
    "    pred_vs_act_df=pd.DataFrame({'Actual':y_test\n",
    "                                 ,'PredictionClass':predictions\n",
    "                                ,'Diff':equal_index_array(l1=y_test,l2=predictions)})\n",
    "    \n",
    "    model_metric=model_metrics(testActualVal=y_test, predictions=predictions, verbose=True)\n",
    "    \n",
    "    \n",
    "    scores = cross_val_score(GaussianNB(), X, y, scoring='accuracy', cv=5)\n",
    "    print(scores)\n",
    "\n",
    "    cv_rmse = scores**0.5\n",
    "    print(\"Avg Accuracy score over 5 folds: \\n\", np.mean(cv_rmse))\n",
    "    print(\"Stddev Accuracy score over 5 folds: \\n\", np.std(cv_rmse))\n",
    "    \n",
    "    model_metric['ClassificationRep']['Classification Time']=end-start\n",
    "    result_dict={}\n",
    "    result_dict['Model']=model\n",
    "    result_dict['Classification_Time']=end-start\n",
    "    result_dict['Actual vs Prediction']=pred_vs_act_df\n",
    "    result_dict['Accuracy']=model_metric['Accuracy']\n",
    "    result_dict['Confusion']=model_metric['Confusion']\n",
    "    result_dict['ClassificationRep']=model_metric['ClassificationRep']\n",
    "    result_dict['CrossVal_Acc_Mean']=np.mean(cv_rmse)\n",
    "    result_dict['CrossVal_Acc_Mean']=np.std(cv_rmse)\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a07eeb",
   "metadata": {},
   "source": [
    "# Create a model using my SKLearn estimator\n",
    "Note: as long as the same random_state and test size is present they'll both work on the same set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "986c816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_my_naive_bayes(X,y,plot_comp,scaler='Standard',random_state=14395076, assess=True,test_size=0.33, verbose=True):\n",
    "    \"\"\"Create a model using My Naive Bayes\"\"\"\n",
    "    \n",
    "\n",
    "    print(\"\"\"\n",
    "-\n",
    "My NAIVE BAYES:\n",
    "-\n",
    "           \n",
    "          \"\"\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X \n",
    "                                                        ,y\n",
    "                                                        ,random_state=random_state\n",
    "                                                        ,test_size=test_size)\n",
    "    \n",
    "    if scaler=='Standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler=='MinMax':    \n",
    "        scaler = MinMaxScaler()\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    start=time.perf_counter()\n",
    "    #Create the DT Regression\n",
    "    model = MyGaussianNB()\n",
    "\n",
    "    #Fit the data\n",
    "    model.fit(X_train,y_train)\n",
    "   \n",
    "    \n",
    "    #Check the predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    end=time.perf_counter()\n",
    "    \n",
    "    print(\"Total Time to Classify: {}\".format(end-start))\n",
    "    \n",
    "    #Results\n",
    "    pred_vs_act_df=pd.DataFrame({'Actual':y_test\n",
    "                                 ,'PredictionClass':predictions\n",
    "                                ,'Diff':equal_index_array(l1=y_test,l2=predictions)})\n",
    "    \n",
    "    model_metric=model_metrics(testActualVal=y_test, predictions=predictions, verbose=True)\n",
    "    \n",
    "    \n",
    "    scores = cross_val_score(MyGaussianNB(), X, y, scoring='accuracy', cv=5)\n",
    "    print(scores)\n",
    "\n",
    "    cv_rmse = scores**0.5\n",
    "    print(\"Avg Accuracy score over 5 folds: \\n\", np.mean(cv_rmse))\n",
    "    print(\"Stddev Accuracy score over 5 folds: \\n\", np.std(cv_rmse))\n",
    "    \n",
    "    model_metric['ClassificationRep']['Classification Time']=end-start\n",
    "    result_dict={}\n",
    "    result_dict['Model']=model\n",
    "    result_dict['Classification_Time']=end-start\n",
    "    result_dict['Actual vs Prediction']=pred_vs_act_df\n",
    "    result_dict['Accuracy']=model_metric['Accuracy']\n",
    "    result_dict['Confusion']=model_metric['Confusion']\n",
    "    result_dict['ClassificationRep']=model_metric['ClassificationRep']\n",
    "    result_dict['CrossVal_Acc_Mean']=np.mean(cv_rmse)\n",
    "    result_dict['CrossVal_Acc_Mean']=np.std(cv_rmse)\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41ee347",
   "metadata": {},
   "source": [
    "# For a single dataset, create both models and add them to the same dataframe for that file for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de8265f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_single_dataset(filename,x_columns,y_column,random_state=14395076,test_size=0.33,scaler='Standard'):\n",
    "    \"\"\"A function to test a single dataset\"\"\"\n",
    "    \n",
    "    #Read in the data\n",
    "    df=pd.read_csv(filename)\n",
    "    X=df[x_columns].values\n",
    "    y=df.pop(y_column[0]).astype(str).values\n",
    "    \n",
    "    my_dict=create_model(X,y,scaler='Standard',random_state=random_state,plot_comp=True,assess=True,test_size=0.33, verbose=True,mod_type='My Naive Bayes')\n",
    "    sk_dict=create_model(X,y,scaler='Standard',random_state=random_state,plot_comp=True,assess=True,test_size=0.33, verbose=True,mod_type='SK Naive Bayes')\n",
    "    \n",
    "    \n",
    "    my_df=pd.DataFrame(my_dict['ClassificationRep'])\n",
    "    sk_df=pd.DataFrame(sk_dict['ClassificationRep'])\n",
    "    \n",
    "    my_df['Type']='MyGaussianNaiveBayes'\n",
    "    sk_df['Type']='SKGaussianNaiveBayes'\n",
    "    \n",
    "    report_df=pd.concat([my_df,sk_df])\n",
    "    \n",
    "    return report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6927c761",
   "metadata": {},
   "source": [
    "# A function to run the single comparison on all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a448846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_datasets(dataset_dictionary):\n",
    "    \"\"\"A function to test on all datasets consistently\"\"\"\n",
    "    \n",
    "    report_dictionary=dict()\n",
    "    df_list=[]\n",
    "    \n",
    "    for file in dataset_dictionary:\n",
    "        file_dictionary=dataset_dictionary[file]\n",
    "        \n",
    "        fp=file_dictionary['filepath']\n",
    "        x_columns=file_dictionary['x_columns']\n",
    "        y_columns=file_dictionary['y_column']\n",
    "        \n",
    "        \n",
    "        print(\n",
    "    \"\"\"\n",
    "---------------\n",
    "---------------   \n",
    "\n",
    "BEGIN TESTING ON - {}:\n",
    "\n",
    "---------------\n",
    "---------------\n",
    "    \"\"\".format(file))\n",
    "\n",
    "        single_report_dict=test_on_single_dataset(filename=fp\n",
    "                               ,x_columns=x_columns\n",
    "                               ,y_column=y_columns\n",
    "                               ,random_state=14395076\n",
    "                               ,test_size=0.33\n",
    "                               ,scaler='Standard')\n",
    "        \n",
    "        single_report_dict['File']=file\n",
    "        single_report_dict.set_index(['File','Type',single_report_dict.index],inplace=True)\n",
    "        df_list+=[single_report_dict]\n",
    "        \n",
    "        report_dictionary[file]=single_report_dict\n",
    "\n",
    "    #full_report_df=pd.concat(df_list)\n",
    "    \n",
    "    return report_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040015b9",
   "metadata": {},
   "source": [
    "# Display the reports in a Notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69dbd68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_all_reports(dataset_dictionary,reports_per_file):\n",
    "    \"\"\"A function to display all reports\"\"\"\n",
    "    \n",
    "    for file in dataset_dictionary:\n",
    "        display(reports_per_file[file].T)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfdae2f",
   "metadata": {},
   "source": [
    "# Define the Files to Test.\n",
    "\n",
    "They should be in the format:\n",
    "\n",
    "test_dictionary:{filename:\n",
    "                        {filepath,\n",
    "                        target_column,\n",
    "                        feature_columns}\n",
    "                  }\n",
    "                  \n",
    "Validation Is NOT DONE on the files e.g. to ensure values are numeric/non-numeric - This should be done as a preprocessing step. The functions above assume this work is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4c32b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets={\n",
    "    'penguins':\n",
    "        {\n",
    "            'filepath':'./Test Datasets/penguins_af.csv'\n",
    "            ,'y_column':['species']\n",
    "            ,'x_columns':['bill_length_mm','flipper_length_mm','body_mass_g','bill_depth_mm']\n",
    "        }\n",
    "    ,'diabetes':\n",
    "        {\n",
    "            'filepath':'./Test Datasets/diabetes.csv'\n",
    "            ,'y_column':['neg_pos']\n",
    "            ,'x_columns':['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
    "        }\n",
    "    ,'glass':\n",
    "        {\n",
    "            'filepath':'./Test Datasets/glassV2.csv'\n",
    "            ,'y_column':['Type']\n",
    "            ,'x_columns':['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe']\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd0665",
   "metadata": {},
   "source": [
    "# Test all of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab3676f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------\n",
      "---------------   \n",
      "\n",
      "BEGIN TESTING ON - penguins:\n",
      "\n",
      "---------------\n",
      "---------------\n",
      "    \n",
      "\n",
      "-\n",
      "My NAIVE BAYES:\n",
      "-\n",
      "           \n",
      "          \n",
      "Total Time to Classify: 0.007652750000000097\n",
      "----DETAIL----\n",
      "\n",
      "\n",
      "Accuracy: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9545454545454546"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[50,  1,  0],\n",
       "       [ 4, 17,  0],\n",
       "       [ 0,  0, 38]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Classification report:\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Adelie': {'precision': 0.9259259259259259,\n",
       "  'recall': 0.9803921568627451,\n",
       "  'f1-score': 0.9523809523809523,\n",
       "  'support': 51},\n",
       " 'Chinstrap': {'precision': 0.9444444444444444,\n",
       "  'recall': 0.8095238095238095,\n",
       "  'f1-score': 0.8717948717948718,\n",
       "  'support': 21},\n",
       " 'Gentoo': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 38},\n",
       " 'accuracy': 0.9545454545454546,\n",
       " 'macro avg': {'precision': 0.95679012345679,\n",
       "  'recall': 0.9299719887955181,\n",
       "  'f1-score': 0.9413919413919413,\n",
       "  'support': 110},\n",
       " 'weighted avg': {'precision': 0.955050505050505,\n",
       "  'recall': 0.9545454545454546,\n",
       "  'f1-score': 0.9534465534465534,\n",
       "  'support': 110}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98507463 0.95522388 0.95522388 0.96969697 0.98484848]\n",
      "Avg Accuracy score over 5 folds: \n",
      " 0.9848695244513902\n",
      "Stddev Accuracy score over 5 folds: \n",
      " 0.006751912908470249\n",
      "\n",
      "-\n",
      "SKLEARN NAIVE BAYES:\n",
      "-\n",
      "          \n",
      "          \n",
      "Total Time to Classify: 0.0008684579999997943\n",
      "----DETAIL----\n",
      "\n",
      "\n",
      "Accuracy: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9545454545454546"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[50,  1,  0],\n",
       "       [ 4, 17,  0],\n",
       "       [ 0,  0, 38]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Classification report:\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Adelie': {'precision': 0.9259259259259259,\n",
       "  'recall': 0.9803921568627451,\n",
       "  'f1-score': 0.9523809523809523,\n",
       "  'support': 51},\n",
       " 'Chinstrap': {'precision': 0.9444444444444444,\n",
       "  'recall': 0.8095238095238095,\n",
       "  'f1-score': 0.8717948717948718,\n",
       "  'support': 21},\n",
       " 'Gentoo': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 38},\n",
       " 'accuracy': 0.9545454545454546,\n",
       " 'macro avg': {'precision': 0.95679012345679,\n",
       "  'recall': 0.9299719887955181,\n",
       "  'f1-score': 0.9413919413919413,\n",
       "  'support': 110},\n",
       " 'weighted avg': {'precision': 0.955050505050505,\n",
       "  'recall': 0.9545454545454546,\n",
       "  'f1-score': 0.9534465534465534,\n",
       "  'support': 110}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98507463 0.95522388 0.95522388 0.96969697 0.98484848]\n",
      "Avg Accuracy score over 5 folds: \n",
      " 0.9848695244513902\n",
      "Stddev Accuracy score over 5 folds: \n",
      " 0.006751912908470249\n",
      "\n",
      "---------------\n",
      "---------------   \n",
      "\n",
      "BEGIN TESTING ON - diabetes:\n",
      "\n",
      "---------------\n",
      "---------------\n",
      "    \n",
      "\n",
      "-\n",
      "My NAIVE BAYES:\n",
      "-\n",
      "           \n",
      "          \n",
      "Total Time to Classify: 0.019765999999999728\n",
      "----DETAIL----\n",
      "\n",
      "\n",
      "Accuracy: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7874015748031497"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[141,  26],\n",
       "       [ 28,  59]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Classification report:\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tested_negative': {'precision': 0.834319526627219,\n",
       "  'recall': 0.844311377245509,\n",
       "  'f1-score': 0.8392857142857143,\n",
       "  'support': 167},\n",
       " 'tested_positive': {'precision': 0.6941176470588235,\n",
       "  'recall': 0.6781609195402298,\n",
       "  'f1-score': 0.6860465116279069,\n",
       "  'support': 87},\n",
       " 'accuracy': 0.7874015748031497,\n",
       " 'macro avg': {'precision': 0.7642185868430212,\n",
       "  'recall': 0.7612361483928693,\n",
       "  'f1-score': 0.7626661129568106,\n",
       "  'support': 254},\n",
       " 'weighted avg': {'precision': 0.7862976229955244,\n",
       "  'recall': 0.7874015748031497,\n",
       "  'f1-score': 0.7867982708556779,\n",
       "  'support': 254}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75324675 0.72727273 0.74675325 0.78431373 0.74509804]\n",
      "Avg Accuracy score over 5 folds: \n",
      " 0.8667310233848855\n",
      "Stddev Accuracy score over 5 folds: \n",
      " 0.010687913636962644\n",
      "\n",
      "-\n",
      "SKLEARN NAIVE BAYES:\n",
      "-\n",
      "          \n",
      "          \n",
      "Total Time to Classify: 0.001536874999999771\n",
      "----DETAIL----\n",
      "\n",
      "\n",
      "Accuracy: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7874015748031497"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[141,  26],\n",
       "       [ 28,  59]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Classification report:\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tested_negative': {'precision': 0.834319526627219,\n",
       "  'recall': 0.844311377245509,\n",
       "  'f1-score': 0.8392857142857143,\n",
       "  'support': 167},\n",
       " 'tested_positive': {'precision': 0.6941176470588235,\n",
       "  'recall': 0.6781609195402298,\n",
       "  'f1-score': 0.6860465116279069,\n",
       "  'support': 87},\n",
       " 'accuracy': 0.7874015748031497,\n",
       " 'macro avg': {'precision': 0.7642185868430212,\n",
       "  'recall': 0.7612361483928693,\n",
       "  'f1-score': 0.7626661129568106,\n",
       "  'support': 254},\n",
       " 'weighted avg': {'precision': 0.7862976229955244,\n",
       "  'recall': 0.7874015748031497,\n",
       "  'f1-score': 0.7867982708556779,\n",
       "  'support': 254}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75324675 0.72727273 0.74675325 0.78431373 0.74509804]\n",
      "Avg Accuracy score over 5 folds: \n",
      " 0.8667310233848855\n",
      "Stddev Accuracy score over 5 folds: \n",
      " 0.010687913636962644\n",
      "\n",
      "---------------\n",
      "---------------   \n",
      "\n",
      "BEGIN TESTING ON - glass:\n",
      "\n",
      "---------------\n",
      "---------------\n",
      "    \n",
      "\n",
      "-\n",
      "My NAIVE BAYES:\n",
      "-\n",
      "           \n",
      "          \n",
      "Total Time to Classify: 0.01342995800000013\n",
      "----DETAIL----\n",
      "\n",
      "\n",
      "Accuracy: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47058823529411764"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[12,  5, 11,  0,  0],\n",
       "       [10,  7,  0,  2,  0],\n",
       "       [ 4,  0,  2,  0,  0],\n",
       "       [ 0,  2,  0,  1,  0],\n",
       "       [ 0,  0,  1,  1, 10]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Classification report:\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1': {'precision': 0.46153846153846156,\n",
       "  'recall': 0.42857142857142855,\n",
       "  'f1-score': 0.4444444444444445,\n",
       "  'support': 28},\n",
       " '2': {'precision': 0.5,\n",
       "  'recall': 0.3684210526315789,\n",
       "  'f1-score': 0.4242424242424242,\n",
       "  'support': 19},\n",
       " '3': {'precision': 0.14285714285714285,\n",
       "  'recall': 0.3333333333333333,\n",
       "  'f1-score': 0.2,\n",
       "  'support': 6},\n",
       " '5': {'precision': 0.25,\n",
       "  'recall': 0.3333333333333333,\n",
       "  'f1-score': 0.28571428571428575,\n",
       "  'support': 3},\n",
       " '7': {'precision': 1.0,\n",
       "  'recall': 0.8333333333333334,\n",
       "  'f1-score': 0.9090909090909091,\n",
       "  'support': 12},\n",
       " 'accuracy': 0.47058823529411764,\n",
       " 'macro avg': {'precision': 0.47087912087912087,\n",
       "  'recall': 0.45939849624060153,\n",
       "  'f1-score': 0.4526984126984127,\n",
       "  'support': 68},\n",
       " 'weighted avg': {'precision': 0.5298561732385262,\n",
       "  'recall': 0.47058823529411764,\n",
       "  'f1-score': 0.4922247686953569,\n",
       "  'support': 68}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31707317 0.34146341 0.36585366 0.43902439 0.09756098]\n",
      "Avg Accuracy score over 5 folds: \n",
      " 0.5454472550595352\n",
      "Stddev Accuracy score over 5 folds: \n",
      " 0.12117101096895212\n",
      "\n",
      "-\n",
      "SKLEARN NAIVE BAYES:\n",
      "-\n",
      "          \n",
      "          \n",
      "Total Time to Classify: 0.0011702499999999283\n",
      "----DETAIL----\n",
      "\n",
      "\n",
      "Accuracy: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47058823529411764"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[12,  5, 11,  0,  0],\n",
       "       [10,  7,  0,  2,  0],\n",
       "       [ 4,  0,  2,  0,  0],\n",
       "       [ 0,  2,  0,  1,  0],\n",
       "       [ 0,  0,  1,  1, 10]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Classification report:\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1': {'precision': 0.46153846153846156,\n",
       "  'recall': 0.42857142857142855,\n",
       "  'f1-score': 0.4444444444444445,\n",
       "  'support': 28},\n",
       " '2': {'precision': 0.5,\n",
       "  'recall': 0.3684210526315789,\n",
       "  'f1-score': 0.4242424242424242,\n",
       "  'support': 19},\n",
       " '3': {'precision': 0.14285714285714285,\n",
       "  'recall': 0.3333333333333333,\n",
       "  'f1-score': 0.2,\n",
       "  'support': 6},\n",
       " '5': {'precision': 0.25,\n",
       "  'recall': 0.3333333333333333,\n",
       "  'f1-score': 0.28571428571428575,\n",
       "  'support': 3},\n",
       " '7': {'precision': 1.0,\n",
       "  'recall': 0.8333333333333334,\n",
       "  'f1-score': 0.9090909090909091,\n",
       "  'support': 12},\n",
       " 'accuracy': 0.47058823529411764,\n",
       " 'macro avg': {'precision': 0.47087912087912087,\n",
       "  'recall': 0.45939849624060153,\n",
       "  'f1-score': 0.4526984126984127,\n",
       "  'support': 68},\n",
       " 'weighted avg': {'precision': 0.5298561732385262,\n",
       "  'recall': 0.47058823529411764,\n",
       "  'f1-score': 0.4922247686953569,\n",
       "  'support': 68}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31707317 0.34146341 0.36585366 0.43902439 0.2195122 ]\n",
      "Avg Accuracy score over 5 folds: \n",
      " 0.5766820074372563\n",
      "Stddev Accuracy score over 5 folds: \n",
      " 0.06342892204503187\n"
     ]
    }
   ],
   "source": [
    "reports_per_file=test_on_datasets(dataset_dictionary=test_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bf7edb",
   "metadata": {},
   "source": [
    "# We observe equality in the results which we are seeing between the SKLearn and My implementation.\n",
    "\n",
    "However, we see the sklearn implementation is considerably faster.\n",
    "\n",
    "While I tried to use only numpy arrays hoping that this would lead to decent performance, we see that the SKLearn implementation is at least one order of magnitude faster than my implementation in all datasets. My assumption is that SKLearn also stores considerably few variables than I store, so is likely a more optimal approach in regards to both space and time complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0471a4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>File</th>\n",
       "      <th colspan=\"8\" halign=\"left\">penguins</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <th colspan=\"4\" halign=\"left\">MyGaussianNaiveBayes</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SKGaussianNaiveBayes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adelie</th>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinstrap</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gentoo</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.956790</td>\n",
       "      <td>0.929972</td>\n",
       "      <td>0.941392</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>0.956790</td>\n",
       "      <td>0.929972</td>\n",
       "      <td>0.941392</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.955051</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.953447</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>0.955051</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.953447</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classification Time</th>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.000868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "File                            penguins                                  \\\n",
       "Type                MyGaussianNaiveBayes                                   \n",
       "                               precision    recall  f1-score     support   \n",
       "Adelie                          0.925926  0.980392  0.952381   51.000000   \n",
       "Chinstrap                       0.944444  0.809524  0.871795   21.000000   \n",
       "Gentoo                          1.000000  1.000000  1.000000   38.000000   \n",
       "accuracy                        0.954545  0.954545  0.954545    0.954545   \n",
       "macro avg                       0.956790  0.929972  0.941392  110.000000   \n",
       "weighted avg                    0.955051  0.954545  0.953447  110.000000   \n",
       "Classification Time             0.007653  0.007653  0.007653    0.007653   \n",
       "\n",
       "File                                                                      \n",
       "Type                SKGaussianNaiveBayes                                  \n",
       "                               precision    recall  f1-score     support  \n",
       "Adelie                          0.925926  0.980392  0.952381   51.000000  \n",
       "Chinstrap                       0.944444  0.809524  0.871795   21.000000  \n",
       "Gentoo                          1.000000  1.000000  1.000000   38.000000  \n",
       "accuracy                        0.954545  0.954545  0.954545    0.954545  \n",
       "macro avg                       0.956790  0.929972  0.941392  110.000000  \n",
       "weighted avg                    0.955051  0.954545  0.953447  110.000000  \n",
       "Classification Time             0.000868  0.000868  0.000868    0.000868  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>File</th>\n",
       "      <th colspan=\"8\" halign=\"left\">diabetes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <th colspan=\"4\" halign=\"left\">MyGaussianNaiveBayes</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SKGaussianNaiveBayes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tested_negative</th>\n",
       "      <td>0.834320</td>\n",
       "      <td>0.844311</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.834320</td>\n",
       "      <td>0.844311</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>167.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_positive</th>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.678161</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.678161</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.787402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.764219</td>\n",
       "      <td>0.761236</td>\n",
       "      <td>0.762666</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>0.764219</td>\n",
       "      <td>0.761236</td>\n",
       "      <td>0.762666</td>\n",
       "      <td>254.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.786298</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.786798</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>0.786298</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.786798</td>\n",
       "      <td>254.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classification Time</th>\n",
       "      <td>0.019766</td>\n",
       "      <td>0.019766</td>\n",
       "      <td>0.019766</td>\n",
       "      <td>0.019766</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.001537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "File                            diabetes                                  \\\n",
       "Type                MyGaussianNaiveBayes                                   \n",
       "                               precision    recall  f1-score     support   \n",
       "tested_negative                 0.834320  0.844311  0.839286  167.000000   \n",
       "tested_positive                 0.694118  0.678161  0.686047   87.000000   \n",
       "accuracy                        0.787402  0.787402  0.787402    0.787402   \n",
       "macro avg                       0.764219  0.761236  0.762666  254.000000   \n",
       "weighted avg                    0.786298  0.787402  0.786798  254.000000   \n",
       "Classification Time             0.019766  0.019766  0.019766    0.019766   \n",
       "\n",
       "File                                                                      \n",
       "Type                SKGaussianNaiveBayes                                  \n",
       "                               precision    recall  f1-score     support  \n",
       "tested_negative                 0.834320  0.844311  0.839286  167.000000  \n",
       "tested_positive                 0.694118  0.678161  0.686047   87.000000  \n",
       "accuracy                        0.787402  0.787402  0.787402    0.787402  \n",
       "macro avg                       0.764219  0.761236  0.762666  254.000000  \n",
       "weighted avg                    0.786298  0.787402  0.786798  254.000000  \n",
       "Classification Time             0.001537  0.001537  0.001537    0.001537  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>File</th>\n",
       "      <th colspan=\"8\" halign=\"left\">glass</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <th colspan=\"4\" halign=\"left\">MyGaussianNaiveBayes</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SKGaussianNaiveBayes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.470879</td>\n",
       "      <td>0.459398</td>\n",
       "      <td>0.452698</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.470879</td>\n",
       "      <td>0.459398</td>\n",
       "      <td>0.452698</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.529856</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.492225</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.529856</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.492225</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classification Time</th>\n",
       "      <td>0.013430</td>\n",
       "      <td>0.013430</td>\n",
       "      <td>0.013430</td>\n",
       "      <td>0.013430</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.001170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "File                               glass                                 \\\n",
       "Type                MyGaussianNaiveBayes                                  \n",
       "                               precision    recall  f1-score    support   \n",
       "1                               0.461538  0.428571  0.444444  28.000000   \n",
       "2                               0.500000  0.368421  0.424242  19.000000   \n",
       "3                               0.142857  0.333333  0.200000   6.000000   \n",
       "5                               0.250000  0.333333  0.285714   3.000000   \n",
       "7                               1.000000  0.833333  0.909091  12.000000   \n",
       "accuracy                        0.470588  0.470588  0.470588   0.470588   \n",
       "macro avg                       0.470879  0.459398  0.452698  68.000000   \n",
       "weighted avg                    0.529856  0.470588  0.492225  68.000000   \n",
       "Classification Time             0.013430  0.013430  0.013430   0.013430   \n",
       "\n",
       "File                                                                     \n",
       "Type                SKGaussianNaiveBayes                                 \n",
       "                               precision    recall  f1-score    support  \n",
       "1                               0.461538  0.428571  0.444444  28.000000  \n",
       "2                               0.500000  0.368421  0.424242  19.000000  \n",
       "3                               0.142857  0.333333  0.200000   6.000000  \n",
       "5                               0.250000  0.333333  0.285714   3.000000  \n",
       "7                               1.000000  0.833333  0.909091  12.000000  \n",
       "accuracy                        0.470588  0.470588  0.470588   0.470588  \n",
       "macro avg                       0.470879  0.459398  0.452698  68.000000  \n",
       "weighted avg                    0.529856  0.470588  0.492225  68.000000  \n",
       "Classification Time             0.001170  0.001170  0.001170   0.001170  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_all_reports(dataset_dictionary=test_datasets,reports_per_file=reports_per_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8795bf3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Manual Intervention\n",
    "\n",
    "For the purposes of assessment, here is a Notebook Section which can be modified directly to pass in values without working through the entire code above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a962b7d0",
   "metadata": {},
   "source": [
    "1. Run this bit to read in the DF and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "476d824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify Here to pass in X and Y\n",
    "scaler='Standard'\n",
    "\n",
    "df=pd.read_csv(test_datasets['penguins']['filepath'])\n",
    "\n",
    "\n",
    "X=df[test_datasets['penguins']['x_columns']].values\n",
    "y=df.pop(test_datasets['penguins']['y_column'][0]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7757e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X \n",
    "                                                    ,y\n",
    "                                                    ,random_state=14395076\n",
    "                                                    ,test_size=0.33)\n",
    "\n",
    "if scaler=='Standard':\n",
    "    scaler = StandardScaler()\n",
    "elif scaler=='MinMax':    \n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedb97f2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "2. Run this bit to test on MyGaussianNaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1963c29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----DETAIL----\n",
      "\n",
      "\n",
      "Accuracy: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9545454545454546"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[50,  1,  0],\n",
       "       [ 4, 17,  0],\n",
       "       [ 0,  0, 38]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Classification report:\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Adelie': {'precision': 0.9259259259259259,\n",
       "  'recall': 0.9803921568627451,\n",
       "  'f1-score': 0.9523809523809523,\n",
       "  'support': 51},\n",
       " 'Chinstrap': {'precision': 0.9444444444444444,\n",
       "  'recall': 0.8095238095238095,\n",
       "  'f1-score': 0.8717948717948718,\n",
       "  'support': 21},\n",
       " 'Gentoo': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 38},\n",
       " 'accuracy': 0.9545454545454546,\n",
       " 'macro avg': {'precision': 0.95679012345679,\n",
       "  'recall': 0.9299719887955181,\n",
       "  'f1-score': 0.9413919413919413,\n",
       "  'support': 110},\n",
       " 'weighted avg': {'precision': 0.955050505050505,\n",
       "  'recall': 0.9545454545454546,\n",
       "  'f1-score': 0.9534465534465534,\n",
       "  'support': 110}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98507463 0.95522388 0.95522388 0.96969697 0.98484848]\n",
      "Avg Accuracy score over 5 folds: \n",
      " 0.9848695244513902\n",
      "Stddev Accuracy score over 5 folds: \n",
      " 0.006751912908470249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': MyGaussianNB(),\n",
       " 'Actual vs Prediction':         Actual PredictionClass  Diff\n",
       " 0       Adelie          Adelie  True\n",
       " 1       Gentoo          Gentoo  True\n",
       " 2       Adelie          Adelie  True\n",
       " 3       Adelie          Adelie  True\n",
       " 4       Gentoo          Gentoo  True\n",
       " ..         ...             ...   ...\n",
       " 105     Adelie          Adelie  True\n",
       " 106  Chinstrap       Chinstrap  True\n",
       " 107     Gentoo          Gentoo  True\n",
       " 108  Chinstrap       Chinstrap  True\n",
       " 109     Adelie          Adelie  True\n",
       " \n",
       " [110 rows x 3 columns],\n",
       " 'Accuracy': 0.9545454545454546,\n",
       " 'Confusion': array([[50,  1,  0],\n",
       "        [ 4, 17,  0],\n",
       "        [ 0,  0, 38]]),\n",
       " 'ClassificationRep': {'Adelie': {'precision': 0.9259259259259259,\n",
       "   'recall': 0.9803921568627451,\n",
       "   'f1-score': 0.9523809523809523,\n",
       "   'support': 51},\n",
       "  'Chinstrap': {'precision': 0.9444444444444444,\n",
       "   'recall': 0.8095238095238095,\n",
       "   'f1-score': 0.8717948717948718,\n",
       "   'support': 21},\n",
       "  'Gentoo': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 38},\n",
       "  'accuracy': 0.9545454545454546,\n",
       "  'macro avg': {'precision': 0.95679012345679,\n",
       "   'recall': 0.9299719887955181,\n",
       "   'f1-score': 0.9413919413919413,\n",
       "   'support': 110},\n",
       "  'weighted avg': {'precision': 0.955050505050505,\n",
       "   'recall': 0.9545454545454546,\n",
       "   'f1-score': 0.9534465534465534,\n",
       "   'support': 110}},\n",
       " 'CrossVal_Acc_Mean': 0.006751912908470249}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Create the DT Regression\n",
    "model = MyGaussianNB()\n",
    "\n",
    "#Fit the data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#Check the predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#Results\n",
    "pred_vs_act_df=pd.DataFrame({'Actual':y_test\n",
    "                             ,'PredictionClass':predictions\n",
    "                            ,'Diff':equal_index_array(l1=y_test,l2=predictions)})\n",
    "\n",
    "model_metric=model_metrics(testActualVal=y_test, predictions=predictions, verbose=True)\n",
    "\n",
    "\n",
    "scores = cross_val_score(MyGaussianNB(), X, y, scoring='accuracy', cv=5)\n",
    "print(scores)\n",
    "\n",
    "cv_rmse = scores**0.5\n",
    "print(\"Avg Accuracy score over 5 folds: \\n\", np.mean(cv_rmse))\n",
    "print(\"Stddev Accuracy score over 5 folds: \\n\", np.std(cv_rmse))\n",
    "\n",
    "\n",
    "result_dict={}\n",
    "result_dict['Model']=model\n",
    "result_dict['Actual vs Prediction']=pred_vs_act_df\n",
    "result_dict['Accuracy']=model_metric['Accuracy']\n",
    "result_dict['Confusion']=model_metric['Confusion']\n",
    "result_dict['ClassificationRep']=model_metric['ClassificationRep']\n",
    "result_dict['CrossVal_Acc_Mean']=np.mean(cv_rmse)\n",
    "result_dict['CrossVal_Acc_Mean']=np.std(cv_rmse)\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbcc62f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "3. Run this bit to test on SK Learns' GaussianNaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b96608a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----DETAIL----\n",
      "\n",
      "\n",
      "Accuracy: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9545454545454546"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[50,  1,  0],\n",
       "       [ 4, 17,  0],\n",
       "       [ 0,  0, 38]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Classification report:\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Adelie': {'precision': 0.9259259259259259,\n",
       "  'recall': 0.9803921568627451,\n",
       "  'f1-score': 0.9523809523809523,\n",
       "  'support': 51},\n",
       " 'Chinstrap': {'precision': 0.9444444444444444,\n",
       "  'recall': 0.8095238095238095,\n",
       "  'f1-score': 0.8717948717948718,\n",
       "  'support': 21},\n",
       " 'Gentoo': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 38},\n",
       " 'accuracy': 0.9545454545454546,\n",
       " 'macro avg': {'precision': 0.95679012345679,\n",
       "  'recall': 0.9299719887955181,\n",
       "  'f1-score': 0.9413919413919413,\n",
       "  'support': 110},\n",
       " 'weighted avg': {'precision': 0.955050505050505,\n",
       "  'recall': 0.9545454545454546,\n",
       "  'f1-score': 0.9534465534465534,\n",
       "  'support': 110}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98507463 0.95522388 0.95522388 0.96969697 0.98484848]\n",
      "Avg Accuracy score over 5 folds: \n",
      " 0.9848695244513902\n",
      "Stddev Accuracy score over 5 folds: \n",
      " 0.006751912908470249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': GaussianNB(),\n",
       " 'Actual vs Prediction':         Actual PredictionClass  Diff\n",
       " 0       Adelie          Adelie  True\n",
       " 1       Gentoo          Gentoo  True\n",
       " 2       Adelie          Adelie  True\n",
       " 3       Adelie          Adelie  True\n",
       " 4       Gentoo          Gentoo  True\n",
       " ..         ...             ...   ...\n",
       " 105     Adelie          Adelie  True\n",
       " 106  Chinstrap       Chinstrap  True\n",
       " 107     Gentoo          Gentoo  True\n",
       " 108  Chinstrap       Chinstrap  True\n",
       " 109     Adelie          Adelie  True\n",
       " \n",
       " [110 rows x 3 columns],\n",
       " 'Accuracy': 0.9545454545454546,\n",
       " 'Confusion': array([[50,  1,  0],\n",
       "        [ 4, 17,  0],\n",
       "        [ 0,  0, 38]]),\n",
       " 'ClassificationRep': {'Adelie': {'precision': 0.9259259259259259,\n",
       "   'recall': 0.9803921568627451,\n",
       "   'f1-score': 0.9523809523809523,\n",
       "   'support': 51},\n",
       "  'Chinstrap': {'precision': 0.9444444444444444,\n",
       "   'recall': 0.8095238095238095,\n",
       "   'f1-score': 0.8717948717948718,\n",
       "   'support': 21},\n",
       "  'Gentoo': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 38},\n",
       "  'accuracy': 0.9545454545454546,\n",
       "  'macro avg': {'precision': 0.95679012345679,\n",
       "   'recall': 0.9299719887955181,\n",
       "   'f1-score': 0.9413919413919413,\n",
       "   'support': 110},\n",
       "  'weighted avg': {'precision': 0.955050505050505,\n",
       "   'recall': 0.9545454545454546,\n",
       "   'f1-score': 0.9534465534465534,\n",
       "   'support': 110}},\n",
       " 'CrossVal_Acc_Mean': 0.006751912908470249}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Create the DT Regression\n",
    "model = GaussianNB()\n",
    "\n",
    "#Fit the data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#Check the predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#Results\n",
    "pred_vs_act_df=pd.DataFrame({'Actual':y_test\n",
    "                             ,'PredictionClass':predictions\n",
    "                            ,'Diff':equal_index_array(l1=y_test,l2=predictions)})\n",
    "\n",
    "model_metric=model_metrics(testActualVal=y_test, predictions=predictions, verbose=True)\n",
    "\n",
    "\n",
    "scores = cross_val_score(MyGaussianNB(), X, y, scoring='accuracy', cv=5)\n",
    "print(scores)\n",
    "\n",
    "cv_rmse = scores**0.5\n",
    "print(\"Avg Accuracy score over 5 folds: \\n\", np.mean(cv_rmse))\n",
    "print(\"Stddev Accuracy score over 5 folds: \\n\", np.std(cv_rmse))\n",
    "\n",
    "\n",
    "result_dict={}\n",
    "result_dict['Model']=model\n",
    "result_dict['Actual vs Prediction']=pred_vs_act_df\n",
    "result_dict['Accuracy']=model_metric['Accuracy']\n",
    "result_dict['Confusion']=model_metric['Confusion']\n",
    "result_dict['ClassificationRep']=model_metric['ClassificationRep']\n",
    "result_dict['CrossVal_Acc_Mean']=np.mean(cv_rmse)\n",
    "result_dict['CrossVal_Acc_Mean']=np.std(cv_rmse)\n",
    "result_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
