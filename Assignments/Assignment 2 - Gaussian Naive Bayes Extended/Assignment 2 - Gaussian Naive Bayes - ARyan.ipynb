{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da1a3d8",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "---\n",
    "\n",
    "Author: Adam Ryan\n",
    "\n",
    "Created Date: 2021-09-14\n",
    "\n",
    "Date Last Modified: 2021-12-07\n",
    "\n",
    "Description: A solution to Assignment 1 and Assignment 2 regarding the implementation of MyGaussianNB which implements Gaussian Naive Bayes.\n",
    "\n",
    "---\n",
    "\n",
    "## Task Description\n",
    "\n",
    "### Objective\n",
    "The objective of this assignment is to implement a Gaussian Naive Bayes classifier in the scikit-learn framework. A notebook (MajorityClassClf) is provided with a simple example of a classifier that works with scikit-learn.\n",
    "\n",
    "Note: The code developed in this assignment will be extended in the second assignment to allow for missing values. \n",
    "\n",
    "### Requirements\n",
    "The notebook MajorityClassClf contains some basic code to help you get started. \n",
    "Provide a python class MyGaussianNB that implements Gaussian Naive Bayes. The conditional probabilities should be calculated as follows:\n",
    "        \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{P}(x_i | y) = \\frac{1}{\\sqrt{2 \\pi (\\sigma_{y_i})^2}} e^{-\\frac{(x_i - \\mu_y)^2}{2(\\sigma_{y_i})^2}} = \\frac{1}{\\sqrt{2 \\pi (\\sigma_{y_i})^2}} \\text{exp}({-\\frac{(x_i - \\mu_y)^2}{2(\\sigma_{y_i})^2}})\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "where ùúáy is the mean for variable i for class y and ùúéy is the corresponding standard deviation. Thereafter the classification should use the NB formulae presented in the lectures. Alternatives that use addition of conditional probabilities or logs should not be used. \n",
    "    \n",
    "The API specification for sklearn classifiers is here: https://scikit-learn.org/stable/developers/develop.html \n",
    "You should implement the ‚Äòfit‚Äô and ‚Äòpredict‚Äô methods, there is no need to implement ‚Äòpredict_proba‚Äô. \n",
    "Prior probabilities should be calculated from the training data. With this, there will be no need to pass parameters when instances are created. \n",
    "\n",
    "Test the performance of your implementation against the GaussianNB implementation in scikit-learn. You should use a range of datasets for this testing. Possible test sets used in lectures are penguins,  diabetes and glassV2. \n",
    "\n",
    "### Submission\n",
    "This is an individual (not group) project. Submission is through the Brightspace page. Your submission should comprise your notebook and the second dataset that you use. Clear all outputs in the notebook before saving for submission. You can use markdown cells in the notebook to report your findings and conclusions. \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Solution - Assignment 1\n",
    "\n",
    "### Explanation\n",
    "\n",
    "1. A function is created which creates models: SK Naive Bayes and My Naive Bayes.\n",
    "2. The My Naive Bayes function is defined. \n",
    "    1. Fit does validation and prepares the class stats for predict.\n",
    "    2. Predict validates it has been fitted. It goes through each row in the test data, and for each row for every class it goes through each column and gets the probability using the Gaussian NB PDF and then derives total row probability for that class. I do not normalise the probabilities across n-many classes as the only piece which matters is the max class. I add this to an array and return it. Validation is done against std.Dev=0 by setting it to the square root of the minimum float in this instance.\n",
    "3. Some functions are defined to create models (MyNaiveBayes and SKLearnBaye) and analyse them.\n",
    "4. Functions are designed to read in all datasets and test my implementation and the default implementation and validate they produce equal classification reports.\n",
    "5. We observe equality in the classification results we are obtaining over the non Missing Set.\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "# Assignment 2 Specific\n",
    "\n",
    "## Objective\n",
    "\n",
    "The objective of this assignment is to explore how missing values can be handled in supervised machine learning. \n",
    "\n",
    "Two strategies will be explored\n",
    "1. Consider missing values explicitly in the classification algorithm (Gaussian Naive Bayes) \n",
    "2. Use imputation methods to guess missing values. \n",
    "\n",
    "## Requirements\n",
    "\n",
    "\n",
    "You may use the code from your submission for the first assignment as your starting point or you may use the sample solution for that assignment that will be provided. \n",
    "\n",
    "### Part 1 \n",
    "\n",
    "Extend the Gaussian Naive Bayes code so that it handles missing values. Gaussian Naive Bayes can handle missing values in training by calculating conditional probabilities on the values that are present. You may choose to put a limit on the number of missing values allowed. \n",
    "\n",
    "Your code should also handle missing values on any test data. The easiest way to do this is to leave features with missing values out of the posterior probability calculation.\n",
    "\n",
    "Comment on any design decisions you make in markup. \n",
    "\n",
    "### Part 2\n",
    "\n",
    "Test the performance of your implementation against the scikit-learn GaussianNB using missing value imputation.\n",
    "\n",
    "Test two imputation options, one univariate and one multi-variate.  To help with your evaluation two versions of the penguins datasets with missing values are provided, one with 20% missing and the other with 40%. \n",
    "\n",
    "You should use cross validation for testing, taking care that any scaling and imputation is handled properly within cross validation.\n",
    "\n",
    "Comment on the results of your evaluation. \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Solution - Assignment 2 Specific - Design Decisions/Implementation Details\n",
    "\n",
    "1. I extend my assignment 1 solution to handle NANs. \n",
    "    \n",
    "    \n",
    "    1. In the fit method, I alter the calculation of the class statistics by modifying methods to calculate based on the non-nan values by using the Numpy NANMean, NANStd, NANProd methods within the \\_\\_set_class_stats() method. I also change the check_x_Y function to include the force_all_finite=False parameter which allows it to contain inf, -inf, and nan values.\n",
    "    \n",
    "    \n",
    "    2. In the predict method, I alter the calculation of the row propbability to use nanprod * class percent. When calculating a probability, in the event that the entire row is nan, np.nanprod(array)=1, and hence the probability for that row becomes the overall class probability within the training set and hence defaults to the majority class. I believe this is a logical/suitable method in the absence of other information. I am highly highly reluctant to filter out data, with the logic being if a user passes a 100 row dataset with 10 NAN rows, the expected outcome in a production environment should be 100 y predictions, not 90 predictions with 10 NANs. While this biases predictions in instances where the training data is misrepresentative or is borderline in terms of weighting, situations which are more significantly skewed are better fit by this approach. In instances where only some of the data is missing, the row probability excludes these missing values from the calculation.\n",
    "    \n",
    "    \n",
    "    3. Outside of the class, I adjust the test_datasets to include the missing value datasets - These produce a default error with default SKLearn implementation so I add a try and except for this case. I also alter the ingestion function to read ? as nan and to consider the first column as an index for the MV dataset.\n",
    "    \n",
    "    \n",
    "    4. For troubleshooting purposes I add a function to show some of the attributes of MyGaussianNB() and to return the models so that I can investigate and verify the probability calculations by performing some spot-checks.\n",
    "    \n",
    "    \n",
    "    5. I enable the ability to not use a scaler but keep the StandardScaler as the default.\n",
    "    \n",
    "    \n",
    "    6. I validate that my changes have not altered the performance on the original dataset.\n",
    "    \n",
    "    \n",
    "    7. One note which might be interesting/useful to overcome scenarios where the bias towards the majority class is undesired would be to allow the user to implement either a probabilistic selection (in the scenario where all are nan, and the user passes 'e.g. binomial' as a parameter, the class selection is made according to that distribution, or alternatively to allow the user to supply weightings to the class percentage (this would essentially serve as the user supplying a Bayesian prior probability as it would capture what the user suspects the ultimate class probability should be within their dataset). As the results of the model were actually surprisingly good with minimal changes over the penguins dataset, I have elected not to include this.\n",
    "  \n",
    "    \n",
    "    8. In the scenario where a user enters an entire column of nulls, I return an error - this should be dealt with in preprocessing and should not be allowed.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "2. I implement the imputation method.\n",
    "\n",
    "\n",
    "    1. I change the create_sk_naive_bayes method to take four possible imputation values, None, KNN, univariate, multivariate.\n",
    "    \n",
    "    \n",
    "    2. This parameter fit transforms the test set, and then uses that on the model generation. \n",
    "    \n",
    "    \n",
    "    3. I adjust the function test_on_single_dataset to run SKLearn's implementation with each of the imputers. All functions take the random state 14395076. I use cross validaiton with 10 folds.\n",
    "    \n",
    "    \n",
    "    4. The report generation function is adjusted to combine the results of each of the runs (MyGNB, SKGNB_NoImpute, SKGNB_meanImpute, SKGNB_iterImpute,SKGNB_KNNImpute) to allow for an easy comparison. I add into the classification report the cross validation scores to have these consolidated in a single location, but they're also outputted during the runs.\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "3. Results of the imputation:\n",
    "\n",
    "\n",
    "    1. Penguins MV 0.2 - This is largely uninteresting, minor differences between Iter/Multi and Mine/Uni.\n",
    "    \n",
    "    \n",
    "    2. Penguins MV 0.4 - This is the more intersting scenario.\n",
    "        \n",
    "        \n",
    "        1. MyNB()\n",
    "        \n",
    "            1. Accuracy: 0.8909090909090909\n",
    "            2. 10-Fold Acc: 0.8705882352941176\n",
    "            3. 10-Fold Stddev: 0.038965332777169584\n",
    "        \n",
    "        2. SKNB() with Mean Imputation\n",
    "        \n",
    "            1. Accuracy: 0.8363636363636363\n",
    "            2. 10-Fold Acc: 0.8498217468805704\n",
    "            3. 10-Fold Stddev: 0.05064279039960052\n",
    "        \n",
    "        3. SKNB() with Itera Imputation\n",
    "        \n",
    "            1. Accuracy: 0.8454545454545455\n",
    "            2. 10-Fold Acc: 0.8374331550802138\n",
    "            3. 10-Fold Stddev: 0.06728459087519195\n",
    "        \n",
    "        4. SKNB() with KNN Imputation\n",
    "        \n",
    "            1. Accuracy: 0.7909090909090909\n",
    "            2. 10-Fold Acc: 0.8195187165775402\n",
    "            3. 10-Fold Stddev: 0.056256088617336775\n",
    "\n",
    "4. Commentary on results: I'm quite surprised that the custom implementation developed is better than the SKLearn with imputation examples. Looking at the cross validation results and standard deviation of CV results, it looks like the differences may not be statistically significant outside of the KNN results with a p value of 0.05 (looking at the values, it looks like taking MyNB as a base and checking+- 2std around the 10-fold accuracy mean that all except KNN Iter would fall within this range) however I was expecting the results to be more balanced. I believe a signficant reason for these results is that as the Penguins dataset is imbalanced towards the majority class, my implementation works 'better' because there's a natural bias towards this class due to how I've implemented it which I believe is elevating the accuracy. Potentially if the dataset was more balanced between classes, we would see more of an equivalence with each approach (as we see Uni and Iter imputation are pretty similar in terms of performance; the KNN imputation is the weakest but this could potentially be fine-tuned with hyperparamter tuning to optimise the number of neighbours to take versus my approach which was to choose 5 neighbours arbitrarily and this clearly has not worked)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f7b8cc",
   "metadata": {},
   "source": [
    "#### Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb0bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####--------------------------------------\n",
    "#00.Import Modules\n",
    "####--------------------------------------\n",
    "\n",
    "\n",
    "######---------BEGIN\n",
    "#      SUPPRESS DEPRECIATION WARNINGS: Applicable to datetime_is_numeric=True\n",
    "######--------END\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "######---------BEGIN\n",
    "#      ML\n",
    "######--------END\n",
    "\n",
    "#import nltk as nl\n",
    "import sklearn as sk\n",
    "#import xgboost as xg\n",
    "#import pymc3 as pymc\n",
    "#import sympy as sym\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score,f1_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "\n",
    "#from sklearn.tree import export_graphviz\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "######---------BEGIN\n",
    "#      SQL\n",
    "######--------END\n",
    "\n",
    "\n",
    "\n",
    "######---------BEGIN\n",
    "#     GENERAL\n",
    "######--------END\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "\n",
    "######---------BEGIN\n",
    "#     DATA VIS\n",
    "######--------END\n",
    "\n",
    "import matplotlib as mp\n",
    "#from bokeh import *\n",
    "#from dash import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88819f56",
   "metadata": {},
   "source": [
    "# My Gaussian Naive Bayes Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919b38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNB(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"A class to capture My Gaussian Naive Bayes\n",
    "    \n",
    "    Input: \n",
    "    BaseEstimator\n",
    "    ClassifierMixin\n",
    "    \n",
    "    Output:\n",
    "    An item of the MGNB class.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialise\n",
    "        \n",
    "        Fit function populates each Attribute.\n",
    "        \n",
    "        Important Note: I am not defining the attributes here, they're merely being documented.\n",
    "        This is done so that the is_fitted method works to validate that the instance has been fitted, and raises an error if not\"\"\"\n",
    "    \n",
    "        #Initial data\n",
    "        ##self.X_=None\n",
    "        ##self.y_=None\n",
    "        \n",
    "        #Unique Class Labels\n",
    "        #self.classes_=None\n",
    "        \n",
    "        #Statistics for each class - Mean, std, Perc\n",
    "        ##self.summary_stats_=dict()\n",
    "        \n",
    "        #Matrix for each Class\n",
    "        ##self.class_dict_=dict()\n",
    "        \n",
    "        #Predict Variables\n",
    "        ##self.X_test_=None\n",
    "        ##self.y_test_=None\n",
    "        \n",
    "        #Cont Table\n",
    "        ##self.cont_dict_=dict()\n",
    "        ##self.raw_dict_=dict()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def fit(self, Xt, yt):\n",
    "        \"\"\"A function to fit the data.\n",
    "        \n",
    "        ---\n",
    "        First it validates the checks \n",
    "        -> Is it a Dataframe, list, or Numpy Array?\n",
    "        -> Is it non-empty?\n",
    "        -> Are they the same size?\n",
    "        -> Is it numeric only?\n",
    "        \n",
    "        Second:\n",
    "        It sets the X and y values\n",
    "        \n",
    "        Third:\n",
    "        It gets the unique clases.\n",
    "        \n",
    "        Fourth:\n",
    "        It gets the summary stats which are needed for the probability calculation for each class.\n",
    "        ---\n",
    "        \n",
    "        I work solely with numpy arrays. \n",
    "        In hindsight it would have been much easier to use Pandas dataframes but I believe numpy is meant to be faster as it's based in C.\n",
    "        \n",
    "        Input:\n",
    "        Xt: List - X values\n",
    "        yt: List - y values\n",
    "        \n",
    "        Output:\n",
    "        ???\"\"\"\n",
    "        \n",
    "        #Validate the type of the inputs -> Note I wrote this before seeing SKLearn recommendation\n",
    "        Xt=self.__validate_input_type(Xt)\n",
    "        yt=self.__validate_input_type(yt)  \n",
    "        \n",
    "        #Validate the training set contains numbers\n",
    "        if not self.__validate_numeric(Xt):\n",
    "            raise ValueError(\"All inputs in the training set should be numeric\")\n",
    "        \n",
    "        if not self.__validate_length(X=Xt,y=yt):\n",
    "            raise ValueError(\"Arrays are of different length\")\n",
    "            \n",
    "        if len(yt)<1:\n",
    "            raise ValueError(\"Empty arrays are not alloweed\")\n",
    "            \n",
    "            \n",
    "        nulls_found_in_all_column=self.__check_if_all_nan(full_set=Xt)\n",
    "\n",
    "        #https://scikit-learn.org/stable/developers/develop.html Recommends using these two instead of the above.\n",
    "        Xt, yt = check_X_y(Xt, yt, force_all_finite=False)\n",
    "        \n",
    "        #Post Validation\n",
    "        self.X_ = Xt\n",
    "        \n",
    "        #Store class labels as strings\n",
    "        self.y_ = np.array(yt, dtype=str)\n",
    "    \n",
    "        \n",
    "        #Set the list of classes\n",
    "        self.classes_ = unique_labels(self.y_)\n",
    "        \n",
    "        #Set the class dictionary\n",
    "        self.__class_dict()\n",
    "        \n",
    "        #Get the stats for each Class and set it\n",
    "        self.__set_class_stats()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"A function to predict a test set.\n",
    "        \n",
    "        Input: \n",
    "        X_test: List/array/dataframe\n",
    "        \n",
    "        Output:\n",
    "        ???\"\"\"\n",
    "        \n",
    "        X_test=self.__validate_input_type(X_test)\n",
    "        \n",
    "        #Validate the test set contains numbers\n",
    "        if not self.__validate_numeric(X_test):\n",
    "            raise ValueError(\"All inputs in the training set should be numeric\")\n",
    "            \n",
    "        #Validate the test set has same column count as training\n",
    "        if not self.__validate_column_count(X_train=self.X_,X_test=X_test):\n",
    "            raise ValueError(\"The test set should have the same column count as the training set\")\n",
    "            \n",
    "            \n",
    "        nulls_found_in_all_column=self.__check_if_all_nan(full_set=X_test)\n",
    "        \n",
    "        X_test = check_array(X_test, accept_sparse=True, force_all_finite=False)\n",
    "    \n",
    "        #Check the model has been fitted -> Returns error if not.\n",
    "        check_is_fitted(self, attributes=['X_','y_','classes_','class_dict_','summary_stats_'],msg='is_fitted_')\n",
    "        \n",
    "        #Passed validation\n",
    "        self.X_test_=X_test\n",
    "        \n",
    "        #BEGIN WITH PREDICTING\n",
    "        y_pred=[]\n",
    "        \n",
    "        column_count=len(X_test[0])\n",
    "        \n",
    "        class_summary_stats=self.get_class_stats()\n",
    "        \n",
    "        row_class_dict=dict()\n",
    "        raw_contingency_dictionary=dict()\n",
    "        \n",
    "        #For each row in the test data, take the row\n",
    "        for row_index in range(len(X_test)):\n",
    "            \n",
    "            #get a single row\n",
    "            row_value=X_test[row_index]\n",
    "            row_class_dict[row_index]=dict()\n",
    "            raw_contingency_dictionary[row_index]=dict()\n",
    "            \n",
    "            #For that row, get the probability values for every class\n",
    "            for class_label in self.get_classes():\n",
    "                \n",
    "                #Empty array to calculate probability for that row\n",
    "                row_list=[]\n",
    "                \n",
    "                #class Stats\n",
    "                class_mean=class_summary_stats[class_label]['Mean']\n",
    "                class_std=class_summary_stats[class_label]['Standard Deviation']\n",
    "                class_percent=class_summary_stats[class_label]['Percent']\n",
    "                \n",
    "                #Go through column for that row and add in probability:\n",
    "                for column_index in range(column_count):\n",
    "                    \n",
    "                    row_list+=[self.__calculate_gaussian_probability(x=row_value[column_index]\n",
    "                                                                         ,mean=class_mean[column_index]\n",
    "                                                                     , std_dev=class_std[column_index])]\n",
    "                        \n",
    "                    \n",
    "\n",
    "                \n",
    "                #This stores the probability values calculated for each row for each class to refer back to later\n",
    "                raw_contingency_dictionary[row_index][class_label]= np.array(row_list)\n",
    "                \n",
    "                #This just stores the probability for that class\n",
    "                row_class_dict[row_index][class_label]= np.nanprod(np.array(row_list)) * class_percent\n",
    "                \n",
    "            \n",
    "            #Probabilities calculated for each class - for that row index get the class:\n",
    "            class_for_row=max(row_class_dict[row_index], key=row_class_dict[row_index].get)\n",
    "            \n",
    "            y_pred+=[class_for_row]\n",
    "            \n",
    "        y_pred=np.array(y_pred)   \n",
    "        self.cont_dict_=row_class_dict\n",
    "        self.raw_dict_=raw_contingency_dictionary\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict_proba(self, Xtes):\n",
    "        \"\"\"A function to predict the probability\"\"\"\n",
    "        pass\n",
    "    # We should really be implementing predict_proba as well.\n",
    "    \n",
    "    \n",
    "    \n",
    "    #A function to get a dictionary for the class\n",
    "    def __class_dict(self):\n",
    "        \"\"\"A function to make a dictionary such that each class is held in the dictionary and all rows of data are put against that class.\n",
    "        \n",
    "        Input: \n",
    "        X -> n-dimensional Array\n",
    "        y -> Single-dimensional array\n",
    "        \n",
    "        Output:\n",
    "        Dictionary -> {Class1:[Row_{1,1},Row_{1,2},...Row_{1,K}]\n",
    "                        ,Class2:[Row_{2,1},...Row_{2,m}]\n",
    "                        ,...\n",
    "                        ,ClassN:[R_{N,1},...R_{N,x}]}\n",
    "        \n",
    "        \"\"\"\n",
    "        class_dict=dict()\n",
    "        \n",
    "        X=self.X_\n",
    "        y=self.y_\n",
    "        \n",
    "        #Each row in the matrix\n",
    "        for row_index in range(len(y)):\n",
    "            \n",
    "            class_value=y[row_index]\n",
    "            \n",
    "            if class_value not in class_dict:\n",
    "                class_dict[class_value]=[np.array(X[row_index])]\n",
    "                \n",
    "            else:\n",
    "                class_dict[class_value]+=[np.array(X[row_index])]\n",
    "                \n",
    "        \n",
    "                \n",
    "        for class_value in self.classes_:\n",
    "            class_dict[class_value]=np.array(class_dict[class_value])\n",
    "            \n",
    "        self.class_dict_=class_dict\n",
    "        \n",
    "        return\n",
    "            \n",
    "    #A function to get the statistics for each class\n",
    "    def __set_class_stats(self):\n",
    "        \"\"\"For each class, get the summary statistics, mainly:\n",
    "        -> Mean, standard dev, percentage of presence\n",
    "        \n",
    "        I.e.:\n",
    "        class1:[Mean_1,std_1,Percent of Total_1]\n",
    "        ,class2:[Mean_2,std_2,Percent of Total_2]\n",
    "        ,...,\n",
    "        classN:[Mean_N,std_N,Percent of Total_N]\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        stat_dict=dict()\n",
    "        \n",
    "        for pred_class in self.classes_:\n",
    "            \n",
    "            #Matrix of classes\n",
    "            class_matrix=self.class_dict_[pred_class]\n",
    "            \n",
    "            #Class:\n",
    "            stat_dict[pred_class]={\n",
    "                                'Mean':self.__get_column_means(class_matrix)\n",
    "                                ,'Standard Deviation':self.__get_column_std_dev(class_matrix)\n",
    "                                ,'Percent':(self.__get_row_count(class_matrix) / len((self.y_)))\n",
    "                                ,'Class Count':(self.__get_row_count(class_matrix))\n",
    "                                }\n",
    "    \n",
    "        \n",
    "        self.summary_stats_=stat_dict\n",
    "        \n",
    "        return\n",
    "        \n",
    "    \n",
    "    #Getter\n",
    "    def get_x(self):\n",
    "        return self.X_\n",
    "    \n",
    "    #Getter\n",
    "    def get_y(self):\n",
    "        return self.y_\n",
    "    \n",
    "    #Getter\n",
    "    def get_classes(self):\n",
    "        return self.classes_\n",
    "    \n",
    "    #Getter\n",
    "    def get_class_dict(self):\n",
    "        return self.class_dict_\n",
    "    \n",
    "    #Getter\n",
    "    def get_class_stats(self):\n",
    "        return self.summary_stats_\n",
    "    \n",
    "\n",
    "    #Getter\n",
    "    def get_raw_dict(self):\n",
    "        return self.raw_dict_\n",
    "    \n",
    "    def get_cont_dict(self):\n",
    "        return cont_dict_\n",
    "                \n",
    "        \n",
    "    #MEANS\n",
    "    @staticmethod   \n",
    "    def __get_column_means(X):\n",
    "        \"\"\"Get the column mean of an Array x\"\"\"\n",
    "        return np.nanmean(X,axis=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def __get_row_means(X):\n",
    "        \"\"\"Get the row mean of an Array x\"\"\"\n",
    "        return np.nanmean(X,axis=1)\n",
    "    \n",
    "    \n",
    "    #Standard Deviations\n",
    "    @staticmethod\n",
    "    def __get_column_std_dev(X):\n",
    "        \"\"\"Get the column std dev of an Array x\"\"\"\n",
    "        return np.nanstd(X,axis=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def __get_row_std_dev(X):\n",
    "        \"\"\"Get the row std dev of an Array x\"\"\"\n",
    "        return np.nanstd(X,axis=1)\n",
    "    \n",
    "    #Counts\n",
    "    @staticmethod   \n",
    "    def __get_column_count(X):\n",
    "        \"\"\"Get the column Count of an Array x\"\"\"\n",
    "        return len(X.T)\n",
    "    \n",
    "    @staticmethod   \n",
    "    def __get_row_count(X):\n",
    "        \"\"\"Get the non NAN row count of an Array x\"\"\"\n",
    "        return len(X)\n",
    "    @staticmethod  \n",
    "    def __check_if_all_nan(full_set):\n",
    "        \"\"\"Check if any columns are all NAN and if so return an error.\"\"\"\n",
    "        \n",
    "        nulls_found=False\n",
    "        \n",
    "        for col_index in range(full_set.shape[1]):\n",
    "\n",
    "            if np.all(np.isnan(full_set[:,col_index])):\n",
    "                nulls_found=True\n",
    "                raise ValueError(\"An entire column in your data is NaN. Please remove this column in preprocessing\")\n",
    "\n",
    "        return nulls_found\n",
    "\n",
    "    \n",
    "    #Probability Function\n",
    "    @staticmethod\n",
    "    def __calculate_gaussian_probability(x, mean, std_dev):\n",
    "        \"\"\"A function to implement the pdf for a gaussian\"\"\"\n",
    "        \n",
    "        if std_dev==0:\n",
    "            #This way squaring it will be well defined\n",
    "            std_dev=sys.float_info.min**(1/2)\n",
    "            \n",
    "        first_term= (1 / (np.sqrt(2 * np.pi) * std_dev))\n",
    "        second_term= (np.exp(-((x-mean)**2 / (2 * (std_dev**2) ))))\n",
    "        gaussian_pdf =  first_term*second_term\n",
    "        \n",
    "        return  gaussian_pdf\n",
    "        \n",
    "    \n",
    "    #Validation\n",
    "    @staticmethod\n",
    "    def __validate_numeric(X):\n",
    "        \"\"\"A function to check that X is a numeric array\"\"\"\n",
    "        return X.dtype.kind in ('b','u','i','f','c')\n",
    "    \n",
    "    #Validation\n",
    "    @staticmethod\n",
    "    def __validate_length(X,y):\n",
    "        \"\"\"A function to check that X and y are equal length\"\"\"\n",
    "        return len(X)==len(y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def __validate_column_count(X_train,X_test):\n",
    "        \"\"\"A function to check that X_train and X_test are equal length\"\"\"\n",
    "        return len(X_train[0])==len(X_test[0])\n",
    "    \n",
    "    @staticmethod\n",
    "    def __validate_input_type(X):\n",
    "        \"\"\"Validate the type of X\"\"\"\n",
    "        if not (isinstance(X,list) or isinstance(X, np.ndarray)):\n",
    "            if isinstance(X,pd.DataFrame):\n",
    "                X=X.to_numpy()\n",
    "                return X\n",
    "\n",
    "            else:\n",
    "                raise TypeError(\"Input must be a list, numpy array, or dataframe\")\n",
    "                \n",
    "        return np.array(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71b264e",
   "metadata": {},
   "source": [
    "# A function to analyse Models and wrap model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58535f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_index_array(l1,l2):\n",
    "    \n",
    "    bool_array=[]\n",
    "    \n",
    "    for pos in range(len(l1)):\n",
    "        bool_array+=[l1[pos]==l2[pos]]\n",
    "        \n",
    "    return bool_array\n",
    "\n",
    "\n",
    "def model_metrics(testActualVal, predictions,verbose=True):\n",
    "    \"\"\"A function to get Metrics for a Model\n",
    "    \n",
    "    Note: This is a function I wrote for the Research Practicum: \n",
    "    https://github.com/Team10UCD/Frontend/blob/cc12998790b7207a859d5089e10f085a65586294/flask/Data_Analytics/Model_Analytics/Route102_sample/02_local_ModelExplorationAndFeatureSelection_Route102.ipynb\"\"\"\n",
    "    \n",
    "    try:\n",
    "        accuracy=metrics.accuracy_score(testActualVal, predictions)\n",
    "    except:\n",
    "        accuracy=None\n",
    "        pass\n",
    "    try:\n",
    "        fscore=metrics.f1_score(testActualVal, predictions)\n",
    "    except:\n",
    "        fscore=None\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        confusion_matrix=metrics.confusion_matrix(testActualVal, predictions)\n",
    "    except:\n",
    "        confusion_matrix=None\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        classification_rep=metrics.classification_report(testActualVal, predictions,output_dict=True)\n",
    "    except:\n",
    "        classification_rep=None\n",
    "        pass\n",
    "    \n",
    "    if verbose:\n",
    "        \n",
    "        try:\n",
    "            print(\"----DETAIL----\")\n",
    "            print(\"\\n\\nAccuracy: \\n\")\n",
    "            display(accuracy)\n",
    "            print(\"\\n\\nConfusion matrix: \\n\")\n",
    "            display(confusion_matrix)\n",
    "            print(\"\\n\\nClassification report:\\n \")\n",
    "            display(classification_rep)\n",
    "            \n",
    "        except:\n",
    "            print(\"----DETAIL----\")\n",
    "            print(\"\\n\\nAccuracy: \\n\", accuracy)\n",
    "            print(\"\\n\\nConfusion matrix: \\n\", confusion_matrix)\n",
    "            print(\"\\n\\nClassification report:\\n \", classification_rep)\n",
    "            \n",
    "    \n",
    "    result_dict={}\n",
    "    result_dict['Accuracy']=accuracy    \n",
    "    result_dict['F1-Score']=fscore\n",
    "    result_dict['Confusion']=confusion_matrix\n",
    "    result_dict['ClassificationRep']=classification_rep\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def create_model(X,y,scaler='Standard',random_state=14395076,imputer=None,plot_comp=True,assess=True,test_size=0.33, verbose=True,mod_type=''):\n",
    "    \"\"\"A wrapper to call the create model function\"\"\"\n",
    "\n",
    "    \n",
    "    if mod_type=='My Naive Bayes':\n",
    "        mod_result=create_my_naive_bayes(X=X\n",
    "                                         ,y=y\n",
    "                                         ,plot_comp=plot_comp\n",
    "                                         ,scaler=scaler\n",
    "                                         ,assess=assess\n",
    "                                         ,random_state=random_state\n",
    "                                         , verbose=verbose\n",
    "                                        ,test_size=test_size)\n",
    "        return mod_result\n",
    "\n",
    "    \n",
    "    \n",
    "    elif mod_type==\"SK Naive Bayes\":\n",
    "        mod_result=create_sk_naive_bayes(X=X\n",
    "                                         ,y=y\n",
    "                                         ,plot_comp=plot_comp\n",
    "                                         ,imputer=imputer\n",
    "                                         ,random_state=random_state\n",
    "                                         ,scaler=scaler\n",
    "                                         ,assess=assess\n",
    "                                         , verbose=verbose\n",
    "                                        ,test_size=test_size)\n",
    "    \n",
    "        return mod_result\n",
    "    \n",
    "    else:\n",
    "        print(\"Sorry, I've not built that yet.\")\n",
    "        raise ValueError(\"Must be My Naive Bayes or SK Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040095e6",
   "metadata": {},
   "source": [
    "# Create a model using the default SKLearn estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe28aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sk_naive_bayes(X,y,plot_comp,scaler='Standard', imputer=None, random_state=14395076,assess=True, test_size=0.33,verbose=True):\n",
    "    \"\"\"Create a model using SK's Naive Bayes.\"\"\"\n",
    "    \n",
    "    \n",
    "    print(\"\"\"\n",
    "-\n",
    "SKLEARN NAIVE BAYES - Imputation Method - {}:\n",
    "-\n",
    "          \n",
    "          \"\"\".format(imputer))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X \n",
    "                                                        ,y\n",
    "                                                        ,random_state=random_state\n",
    "                                                        ,test_size=test_size)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if scaler=='Standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler=='MinMax':    \n",
    "        scaler = MinMaxScaler()\n",
    "    \n",
    "    if scaler in ['Standard','MinMax']:\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    \n",
    "    if imputer=='univariate':\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        X_train = imp.fit_transform(X_train)\n",
    "        X_test = imp.transform(X_test)\n",
    "        \n",
    "    \n",
    "    elif imputer=='multivariate':\n",
    "        imp=IterativeImputer(max_iter=100, random_state=random_state)\n",
    "        X_train = imp.fit_transform(X_train)\n",
    "        X_test = imp.transform(X_test)\n",
    "        \n",
    "    elif imputer=='KNN':\n",
    "        imp = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "        X_train = imp.fit_transform(X_train)\n",
    "        X_test = imp.transform(X_test)\n",
    "        \n",
    "        \n",
    "    start=time.perf_counter()\n",
    "    \n",
    "    #Create the DT Regression\n",
    "    model = GaussianNB()\n",
    "\n",
    "    #Fit the data\n",
    "    model.fit(X_train,y_train)\n",
    "   \n",
    "    \n",
    "    #Check the predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    end=time.perf_counter()\n",
    "    \n",
    "    print(\"Total Time to Classify: {}\".format(end-start))\n",
    "    \n",
    "    \n",
    "    #Results\n",
    "    pred_vs_act_df=pd.DataFrame({'Actual':y_test\n",
    "                                 ,'PredictionClass':predictions\n",
    "                                ,'Diff':equal_index_array(l1=y_test,l2=predictions)})\n",
    "    \n",
    "    model_metric=model_metrics(testActualVal=y_test, predictions=predictions, verbose=True)\n",
    "    \n",
    "    try:\n",
    "        if imputer=='univariate':\n",
    "            imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "            X_cross = imp.fit_transform(X)\n",
    "\n",
    "\n",
    "        elif imputer=='multivariate':\n",
    "            imp=IterativeImputer(max_iter=100, random_state=random_state)\n",
    "            X_cross = imp.fit_transform(X)\n",
    "            \n",
    "        elif imputer=='KNN':\n",
    "            imp = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "            X_cross = imp.fit_transform(X)\n",
    "            \n",
    "        else:\n",
    "            X_cross=X\n",
    "        \n",
    "        scores = cross_val_score(GaussianNB(), X_cross, y, scoring='accuracy', cv=10)\n",
    "        print(scores)\n",
    "    except:\n",
    "        print(\"ERROR\")\n",
    "        pass\n",
    "\n",
    "    cv_rmse = scores #**0.5\n",
    "    print(\"Avg Accuracy score over 10 folds: \\n\", np.mean(cv_rmse))\n",
    "    print(\"Stddev Accuracy score over 10 folds: \\n\", np.std(cv_rmse))\n",
    "    \n",
    "    model_metric['ClassificationRep']['Classification Time']=end-start\n",
    "    result_dict={}\n",
    "    result_dict['Model']=model\n",
    "    result_dict['Classification_Time']=end-start\n",
    "    result_dict['Actual vs Prediction']=pred_vs_act_df\n",
    "    \n",
    "    result_dict['Accuracy']=model_metric['Accuracy']\n",
    "    result_dict['Confusion']=model_metric['Confusion']\n",
    "    \n",
    "    \n",
    "    result_dict['ClassificationRep']=model_metric['ClassificationRep']\n",
    "    result_dict['ClassificationRep']['Cross_Val_Acc_Mean']=np.mean(cv_rmse)\n",
    "    result_dict['ClassificationRep']['Cross_Val_Acc_STD']=np.std(cv_rmse)\n",
    "    \n",
    "    result_dict['CrossVal_Acc_Mean']=np.mean(cv_rmse)\n",
    "    result_dict['CrossVal_Acc_STD']=np.std(cv_rmse)\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a07eeb",
   "metadata": {},
   "source": [
    "# Create a model using my SKLearn estimator\n",
    "Note: as long as the same random_state and test size is present they'll both work on the same set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986c816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_my_naive_bayes(X,y,plot_comp,scaler='Standard',random_state=14395076, assess=True,test_size=0.33, verbose=True):\n",
    "    \"\"\"Create a model using My Naive Bayes\"\"\"\n",
    "    \n",
    "\n",
    "    print(\"\"\"\n",
    "-\n",
    "My NAIVE BAYES:\n",
    "-\n",
    "           \n",
    "          \"\"\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X \n",
    "                                                        ,y\n",
    "                                                        ,random_state=random_state\n",
    "                                                        ,test_size=test_size)\n",
    "    \n",
    "    if scaler=='Standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler=='MinMax':    \n",
    "        scaler = MinMaxScaler()\n",
    "    \n",
    "    if scaler in ['Standard','MinMax']:\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    start=time.perf_counter()\n",
    "    #Create the DT Regression\n",
    "    model = MyGaussianNB()\n",
    "\n",
    "    #Fit the data\n",
    "    model.fit(X_train,y_train)\n",
    "   \n",
    "    \n",
    "    #Check the predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    end=time.perf_counter()\n",
    "    \n",
    "    print(\"Total Time to Classify: {}\".format(end-start))\n",
    "    \n",
    "    #Results\n",
    "    pred_vs_act_df=pd.DataFrame({'Actual':y_test\n",
    "                                 ,'PredictionClass':predictions\n",
    "                                ,'Diff':equal_index_array(l1=y_test,l2=predictions)})\n",
    "    \n",
    "    model_metric=model_metrics(testActualVal=y_test, predictions=predictions, verbose=True)\n",
    "    \n",
    "    \n",
    "    scores = cross_val_score(MyGaussianNB(), X, y, scoring='accuracy', cv=10)\n",
    "    print(scores)\n",
    "\n",
    "    cv_rmse = scores #**0.5\n",
    "    print(\"Avg Accuracy score over 10 folds: \\n\", np.mean(cv_rmse))\n",
    "    print(\"Stddev Accuracy score over 10 folds: \\n\", np.std(cv_rmse))\n",
    "    \n",
    "    model_metric['ClassificationRep']['Classification Time']=end-start\n",
    "    result_dict={}\n",
    "    result_dict['Model']=model\n",
    "    result_dict['Classification_Time']=end-start\n",
    "    result_dict['Actual vs Prediction']=pred_vs_act_df\n",
    "    result_dict['Accuracy']=model_metric['Accuracy']\n",
    "    result_dict['Confusion']=model_metric['Confusion']\n",
    "    \n",
    "    result_dict['ClassificationRep']=model_metric['ClassificationRep']\n",
    "    \n",
    "    result_dict['CrossVal_Acc_Mean']=np.mean(cv_rmse)\n",
    "    result_dict['CrossVal_Acc_STD']=np.std(cv_rmse)\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41ee347",
   "metadata": {},
   "source": [
    "# For a single dataset, create both models and add them to the same dataframe for that file for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8265f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_single_dataset(filename,x_columns,y_column,random_state=14395076,test_size=0.33,scaler='Standard'):\n",
    "    \"\"\"A function to test a single dataset\"\"\"\n",
    "    \n",
    "    #Read in the data\n",
    "    \n",
    "    if filename in ('penguins 0.2','penguins 0.4'):\n",
    "        df=pd.read_csv(filename,index_col=0,na_values = '?')\n",
    "    else:\n",
    "        df=pd.read_csv(filename,na_values = '?')\n",
    "        \n",
    "    X=df[x_columns].values\n",
    "    y=df.pop(y_column[0]).astype(str).values\n",
    "    \n",
    "    use_scaler=scaler\n",
    "    \n",
    "    my_dict=create_model(X,y,scaler=use_scaler,random_state=random_state,plot_comp=True,assess=True,test_size=test_size, verbose=True,mod_type='My Naive Bayes')\n",
    "    \n",
    "    #Protecting against changes to X by imputing\n",
    "    \n",
    "    if filename in ('penguins 0.2','penguins 0.4'):\n",
    "        df=pd.read_csv(filename,index_col=0,na_values = '?')\n",
    "    else:\n",
    "        df=pd.read_csv(filename,na_values = '?')\n",
    "        \n",
    "    X=df[x_columns].values\n",
    "    y=df.pop(y_column[0]).astype(str).values\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        sk_dict_no_Impute=create_model(X,y,scaler=use_scaler,imputer=None, random_state=random_state,plot_comp=True,assess=True,test_size=test_size, verbose=True,mod_type='SK Naive Bayes')\n",
    "    except Exception as e:\n",
    "        sk_dict_no_Impute={'ClassificationRep':dict()}\n",
    "        print(\"DEFAULT SKLEARN ERROR: {}\\n\".format(e))\n",
    "        \n",
    "        \n",
    "    #Protecting against changes to X by imputing  \n",
    "    if filename in ('penguins 0.2','penguins 0.4'):\n",
    "        df=pd.read_csv(filename,index_col=0,na_values = '?')\n",
    "    else:\n",
    "        df=pd.read_csv(filename,na_values = '?')\n",
    "        \n",
    "    X=df[x_columns].values\n",
    "    y=df.pop(y_column[0]).astype(str).values\n",
    "    \n",
    "    try:\n",
    "        sk_dict_uni_Impute=create_model(X,y,scaler=use_scaler,imputer='univariate', random_state=random_state,plot_comp=True,assess=True,test_size=test_size, verbose=True,mod_type='SK Naive Bayes')\n",
    "    except Exception as e:\n",
    "        sk_dict_uni_Impute={'ClassificationRep':dict()}\n",
    "        print(\"UNIVARIATE SKLEARN ERROR: {}\\n\".format(e))\n",
    "        \n",
    "    #Protecting against changes to X by imputing    \n",
    "    if filename in ('penguins 0.2','penguins 0.4'):\n",
    "        df=pd.read_csv(filename,index_col=0,na_values = '?')\n",
    "    else:\n",
    "        df=pd.read_csv(filename,na_values = '?')\n",
    "        \n",
    "    X=df[x_columns].values\n",
    "    y=df.pop(y_column[0]).astype(str).values\n",
    "    \n",
    "    try:\n",
    "        sk_dict_multi_Impute=create_model(X,y,scaler=use_scaler,imputer='multivariate', random_state=random_state,plot_comp=True,assess=True,test_size=test_size, verbose=True,mod_type='SK Naive Bayes')\n",
    "    except Exception as e:\n",
    "        sk_dict_multi_Impute={'ClassificationRep':dict()}\n",
    "        print(\"MULTIARIATE SKLEARN ERROR: {}\\n\".format(e))\n",
    "        \n",
    "        \n",
    "        \n",
    "    #Protecting against changes to X by imputing   \n",
    "    if filename in ('penguins 0.2','penguins 0.4'):\n",
    "        df=pd.read_csv(filename,index_col=0,na_values = '?')\n",
    "    else:\n",
    "        df=pd.read_csv(filename,na_values = '?')\n",
    "        \n",
    "    X=df[x_columns].values\n",
    "    y=df.pop(y_column[0]).astype(str).values\n",
    "\n",
    "    try:\n",
    "        sk_dict_knn_Impute=create_model(X,y,scaler=use_scaler,imputer='KNN', random_state=random_state,plot_comp=True,assess=True,test_size=test_size, verbose=True,mod_type='SK Naive Bayes')\n",
    "    except Exception as e:\n",
    "        sk_dict_knn_Impute={'ClassificationRep':dict()}\n",
    "        print(\"KNN SKLEARN ERROR: {}\\n\".format(e))\n",
    "        \n",
    "    \n",
    "    my_df=pd.DataFrame(my_dict['ClassificationRep'])\n",
    "    sk_df_no_impute=pd.DataFrame(sk_dict_no_Impute['ClassificationRep'])\n",
    "    sk_df_uni_impute=pd.DataFrame(sk_dict_uni_Impute['ClassificationRep'])\n",
    "    sk_df_multi_impute=pd.DataFrame(sk_dict_multi_Impute['ClassificationRep'])\n",
    "    sk_df_knn_impute=pd.DataFrame(sk_dict_knn_Impute['ClassificationRep'])\n",
    "    \n",
    "    my_df['Type']='MyGaussianNB'\n",
    "    sk_df_no_impute['Type']='SKGaussianNB_NoImputer'\n",
    "    sk_df_uni_impute['Type']='SKGaussianNB_UniImputer'\n",
    "    sk_df_multi_impute['Type']='SKGaussianNB_MultiImputer'\n",
    "    sk_df_knn_impute['Type']='SKGaussianNB_KNN_Imputer'\n",
    "    \n",
    "    report_df=pd.concat([my_df,sk_df_no_impute,sk_df_uni_impute,sk_df_multi_impute,sk_df_knn_impute])\n",
    "    \n",
    "    return report_df, my_dict, sk_dict_no_Impute, sk_dict_uni_Impute,sk_dict_multi_Impute, sk_dict_knn_Impute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6927c761",
   "metadata": {},
   "source": [
    "# A function to run the single comparison on all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a448846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_datasets(dataset_dictionary):\n",
    "    \"\"\"A function to test on all datasets consistently\"\"\"\n",
    "    \n",
    "    report_dictionary=dict()\n",
    "    df_list=[]\n",
    "    model_dictionay=dict()\n",
    "    \n",
    "    for file in dataset_dictionary:\n",
    "        file_dictionary=dataset_dictionary[file]\n",
    "        \n",
    "        fp=file_dictionary['filepath']\n",
    "        x_columns=file_dictionary['x_columns']\n",
    "        y_columns=file_dictionary['y_column']\n",
    "        \n",
    "        \n",
    "        print(\n",
    "    \"\"\"\n",
    "---------------\n",
    "---------------   \n",
    "\n",
    "BEGIN TESTING ON - {}:\n",
    "\n",
    "---------------\n",
    "---------------\n",
    "    \"\"\".format(file))\n",
    "\n",
    "        single_report_dict, my_model, sk_dict_no_Impute, sk_dict_uni_Impute, sk_dict_multi_Impute, sk_dict_knn_Impute =test_on_single_dataset(filename=fp\n",
    "                               ,x_columns=x_columns\n",
    "                               ,y_column=y_columns\n",
    "                               ,random_state=14395076\n",
    "                               ,test_size=0.33\n",
    "                               ,scaler='Standard')\n",
    "        \n",
    "        single_report_dict['File']=file\n",
    "        model_dictionay[file]={'Mine': my_model\n",
    "                               ,'SKLearn_NoImute':sk_dict_no_Impute\n",
    "                               ,'SKLearn_UniImute':sk_dict_uni_Impute\n",
    "                              ,'SKLearn_MultiImute':sk_dict_multi_Impute\n",
    "                              ,'SKLearn_KNNImute':sk_dict_knn_Impute\n",
    "                              ,}\n",
    "        \n",
    "        single_report_dict.set_index(['File','Type',single_report_dict.index],inplace=True)\n",
    "        df_list+=[single_report_dict]\n",
    "        \n",
    "        report_dictionary[file]=single_report_dict\n",
    "\n",
    "    #full_report_df=pd.concat(df_list)\n",
    "    \n",
    "    return report_dictionary, model_dictionay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040015b9",
   "metadata": {},
   "source": [
    "# Display the reports in a Notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dbd68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_all_reports(dataset_dictionary,reports_per_file):\n",
    "    \"\"\"A function to display all reports\"\"\"\n",
    "    \n",
    "    for file in dataset_dictionary:\n",
    "        display(reports_per_file[file])\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8447f1",
   "metadata": {},
   "source": [
    "# Check the contingency table and Raw Data for my Model\n",
    "\n",
    "1. While generating the MV data I found it very tricky to understand what was happening in rows where it was all nan.\n",
    "\n",
    "2. Using this method and the model attribtues I was able to identify that np.nanprod([nan])=1 and hence in these instancse it takes the class parameter of the most frequent class.\n",
    "\n",
    "3. Using this format you can access specific data from the model_dictionary. This includes a line-by-line comparison (pre Note for SKLearn unless it's been defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81ffc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_sample_data_for_model(filename,model_dictionary,dataset_dictionary):\n",
    "    \n",
    "    print(\"------------\")\n",
    "    \n",
    "    if filename in dataset_dictionary:\n",
    "        \n",
    "        print(\"\"\"CLASS STATS - {}:\"\"\".format(filename))\n",
    "        display(model_dictionary[filename]['Mine']['Model'].get_class_stats())\n",
    "        print(\"\"\"RAW DATA - {}:\"\"\".format(filename))\n",
    "        display(model_dictionary[filename]['Mine']['Model'].raw_dict_)\n",
    "        print(\"\"\"CONT. TABLE DATA - {}:\"\"\".format(filename))\n",
    "        display(model_dictionary[filename]['Mine']['Model'].cont_dict_)\n",
    "        \n",
    "        print(\"------------\")\n",
    "\n",
    "    else:\n",
    "        print(\"File not found in test datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfdae2f",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "\n",
    "# Assignment Configuration Starts Here\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "\n",
    "# Define the Files to Test.\n",
    "\n",
    "They should be in the format:\n",
    "\n",
    "test_dictionary:{filename:\n",
    "                        {filepath,\n",
    "                        target_column,\n",
    "                        feature_columns}\n",
    "                  }\n",
    "                  \n",
    "Validation Is NOT DONE on the files e.g. to ensure values are numeric/non-numeric - This should be done as a preprocessing step. The functions above assume this work is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c32b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets={\n",
    "    'penguins':\n",
    "        {\n",
    "            'filepath':'./Test Datasets/penguins_af.csv'\n",
    "            ,'y_column':['species']\n",
    "            ,'x_columns':['bill_length_mm','flipper_length_mm','body_mass_g','bill_depth_mm']\n",
    "        }\n",
    "    \n",
    "    ,'penguins 0.2':\n",
    "        {\n",
    "            'filepath':'./Test Datasets/penguinsMV0.2.csv'\n",
    "            ,'y_column':['species']\n",
    "            ,'x_columns':['bill_length','flipper_length','body_mass','bill_depth']\n",
    "        }\n",
    "    \n",
    "    ,'penguins 0.4':\n",
    "        {\n",
    "            'filepath':'./Test Datasets/penguinsMV0.4.csv'\n",
    "            ,'y_column':['species']\n",
    "            ,'x_columns':['bill_length','flipper_length','body_mass','bill_depth']\n",
    "        }\n",
    "    \n",
    "    ,'diabetes':\n",
    "        {\n",
    "            'filepath':'./Test Datasets/diabetes.csv'\n",
    "            ,'y_column':['neg_pos']\n",
    "            ,'x_columns':['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
    "        }\n",
    "    ,'glass':\n",
    "        {\n",
    "            'filepath':'./Test Datasets/glassV2.csv'\n",
    "            ,'y_column':['Type']\n",
    "            ,'x_columns':['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe']\n",
    "        }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "missing_datasets={\n",
    "    'penguins 0.2':\n",
    "        {\n",
    "            'filepath':'./Test Datasets/penguinsMV0.2.csv'\n",
    "            ,'y_column':['species']\n",
    "            ,'x_columns':['bill_length','flipper_length','body_mass','bill_depth']\n",
    "        }\n",
    "    \n",
    "    ,'penguins 0.4':\n",
    "        {\n",
    "            'filepath':'./Test Datasets/penguinsMV0.4.csv'\n",
    "            ,'y_column':['species']\n",
    "            ,'x_columns':['bill_length','flipper_length','body_mass','bill_depth']\n",
    "        }\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd0665",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Test all of the files.\n",
    "\n",
    "## Assignment 2 Commentary\n",
    "\n",
    "1. Running the below cells does the following:\n",
    "    1. It runs model generation (Mine and SKLearn) on all datasets defined in the test_datasets dictionary.\n",
    "    2. We see it successfully runs for the missing value datasets.\n",
    "    3. We see the SKLearn implementation does not run for the missing value datasets by default.\n",
    "    4. We see the other ones impute.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3676f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_per_file, model_dictionary=test_on_datasets(dataset_dictionary=test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0471a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_all_reports(dataset_dictionary=test_datasets,reports_per_file=reports_per_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ffaa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_all_reports(dataset_dictionary=missing_datasets,reports_per_file=reports_per_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c530e4fc",
   "metadata": {},
   "source": [
    "# Checking actual data used.\n",
    "\n",
    "In making the changes, I had difficulty understanding if the values computed were correct. I developed the see_sample_data_for_model to print the raw data (row prob for each class, class stats, etc.) for each case. I used the below which works on both missing sets and non-missing sets so that I could confirm they were adding up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c7efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for name in missing_datasets:\n",
    "for name in test_datasets:\n",
    "    see_sample_data_for_model(name,model_dictionary,dataset_dictionary=test_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8795bf3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Manual Intervention\n",
    "\n",
    "For the purposes of assessment, here is a Notebook Section which can be modified directly to pass in values without working through the entire code above.\n",
    "\n",
    "\n",
    "Note: This was a little bit annoying as trying to seperate out elements caused X and y to be imputed by the previous imputer. This is why the beginning of each involves reading in the file, splitting, etc., to ensure the values are 'fresh'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5186d2ce",
   "metadata": {},
   "source": [
    "## Penguins 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1963c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------READ IN DATA CONFIGURATION---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "#Modify Here to pass in X and Y\n",
    "scaler='Standard'\n",
    "\n",
    "fn='penguins 0.2'\n",
    "fp=test_datasets[fn]['filepath']\n",
    "    \n",
    "if fn in ('penguins 0.2','penguins 0.4'):\n",
    "    df=pd.read_csv(fp,index_col=0,na_values = '?')\n",
    "else:\n",
    "    df=pd.read_csv(fp,na_values = '?')\n",
    "\n",
    "\n",
    "X=df[test_datasets[fn]['x_columns']].values\n",
    "y=df.pop(test_datasets[fn]['y_column'][0]).values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X \n",
    "                                                    ,y\n",
    "                                                    ,random_state=14395076\n",
    "                                                    ,test_size=0.33)\n",
    "\n",
    "if scaler=='Standard':\n",
    "    scaler = StandardScaler()\n",
    "elif scaler=='MinMax':    \n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------MODEL---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "print(\"\"\"\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------Mine - {}---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "\"\"\".format(fn))\n",
    "\n",
    "\n",
    "#Create the DT Regression\n",
    "model = MyGaussianNB()\n",
    "\n",
    "#Fit the data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#Check the predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#Results\n",
    "pred_vs_act_df=pd.DataFrame({'Actual':y_test\n",
    "                             ,'PredictionClass':predictions\n",
    "                            ,'Diff':equal_index_array(l1=y_test,l2=predictions)})\n",
    "\n",
    "model_metric=model_metrics(testActualVal=y_test, predictions=predictions, verbose=True)\n",
    "\n",
    "\n",
    "scores = cross_val_score(MyGaussianNB(), X, y, scoring='accuracy', cv=10)\n",
    "print(scores)\n",
    "\n",
    "cv_rmse = scores #**0.5\n",
    "print(\"Avg Accuracy score over 5 folds: \\n\", np.mean(cv_rmse))\n",
    "print(\"Stddev Accuracy score over 5 folds: \\n\", np.std(cv_rmse))\n",
    "\n",
    "\n",
    "result_dict={}\n",
    "result_dict['Model']=model\n",
    "result_dict['Actual vs Prediction']=pred_vs_act_df\n",
    "result_dict['Accuracy']=model_metric['Accuracy']\n",
    "result_dict['Confusion']=model_metric['Confusion']\n",
    "result_dict['ClassificationRep']=model_metric['ClassificationRep']\n",
    "result_dict['CrossVal_Acc_Mean']=np.mean(cv_rmse)\n",
    "result_dict['CrossVal_Acc_STD']=np.std(cv_rmse)\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e255ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################################\n",
    "\n",
    "    #-------------READ IN DATA CONFIGURATION---------------------#\n",
    "\n",
    "    ##############################################################\n",
    "    \n",
    "\n",
    "    #Modify Here to pass in X and Y\n",
    "    scaler='Standard'\n",
    "\n",
    "    fn='penguins 0.2'\n",
    "    fp=test_datasets[fn]['filepath']\n",
    "\n",
    "    if fn in ('penguins 0.2','penguins 0.4'):\n",
    "        df=pd.read_csv(fp,index_col=0,na_values = '?')\n",
    "    else:\n",
    "        df=pd.read_csv(fp,na_values = '?')\n",
    "\n",
    "\n",
    "    X=df[test_datasets[fn]['x_columns']].values\n",
    "    y=df.pop(test_datasets[fn]['y_column'][0]).values\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X \n",
    "                                                        ,y\n",
    "                                                        ,random_state=14395076\n",
    "                                                        ,test_size=0.33)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"\"\"\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------NO IMPUTER - {}---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "\"\"\".format(fn))\n",
    "\n",
    "    ##############################################################\n",
    "\n",
    "    #-------------MODEL---------------------#\n",
    "\n",
    "    ##############################################################\n",
    "\n",
    "    #Create the DT Regression\n",
    "    model = GaussianNB()\n",
    "\n",
    "    #Fit the data\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "    #Check the predictions\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    #Results\n",
    "    pred_vs_act_df=pd.DataFrame({'Actual':y_test\n",
    "                                 ,'PredictionClass':predictions\n",
    "                                ,'Diff':equal_index_array(l1=y_test,l2=predictions)})\n",
    "\n",
    "    model_metric=model_metrics(testActualVal=y_test, predictions=predictions, verbose=True)\n",
    "\n",
    "\n",
    "    scores = cross_val_score(MyGaussianNB(), X, y, scoring='accuracy', cv=10)\n",
    "    print(scores)\n",
    "\n",
    "    cv_rmse = scores #**0.5\n",
    "    print(\"Avg Accuracy score over 5 folds: \\n\", np.mean(cv_rmse))\n",
    "    print(\"Stddev Accuracy score over 5 folds: \\n\", np.std(cv_rmse))\n",
    "\n",
    "\n",
    "    result_dict={}\n",
    "    result_dict['Model']=model\n",
    "    result_dict['Actual vs Prediction']=pred_vs_act_df\n",
    "    result_dict['Accuracy']=model_metric['Accuracy']\n",
    "    result_dict['Confusion']=model_metric['Confusion']\n",
    "    result_dict['ClassificationRep']=model_metric['ClassificationRep']\n",
    "    result_dict['CrossVal_Acc_Mean']=np.mean(cv_rmse)\n",
    "    result_dict['CrossVal_Acc_STD']=np.std(cv_rmse)\n",
    "    result_dict\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Default SKLearn won't accept NAN - {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb6d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------READ IN DATA CONFIGURATION---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "#Modify Here to pass in X and Y\n",
    "scaler='Standard'\n",
    "\n",
    "fn='penguins 0.2'\n",
    "fp=test_datasets[fn]['filepath']\n",
    "    \n",
    "if fn in ('penguins 0.2','penguins 0.4'):\n",
    "    df=pd.read_csv(fp,index_col=0,na_values = '?')\n",
    "else:\n",
    "    df=pd.read_csv(fp,na_values = '?')\n",
    "\n",
    "\n",
    "X=df[test_datasets[fn]['x_columns']].values\n",
    "y=df.pop(test_datasets[fn]['y_column'][0]).values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X \n",
    "                                                    ,y\n",
    "                                                    ,random_state=14395076\n",
    "                                                    ,test_size=0.33)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X \n",
    "                                                    ,y\n",
    "                                                    ,random_state=14395076\n",
    "                                                    ,test_size=0.33)\n",
    "\n",
    "if scaler=='Standard':\n",
    "    scaler = StandardScaler()\n",
    "elif scaler=='MinMax':    \n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------IMPUTER CONFIGURATION--------------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "imputer='univariate'\n",
    "\n",
    "if imputer=='univariate':\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    X_train = imp.fit_transform(X_train)\n",
    "    X_test = imp.transform(X_test)\n",
    "\n",
    "\n",
    "elif imputer=='multivariate':\n",
    "    imp=IterativeImputer(max_iter=100, random_state=14395076)\n",
    "    X_train = imp.fit_transform(X_train)\n",
    "    X_test = imp.transform(X_test)\n",
    "\n",
    "elif imputer=='KNN':\n",
    "    imp = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "    X_train = imp.fit_transform(X_train)\n",
    "    X_test = imp.transform(X_test)\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\"\"\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------UNI IMPUTER - {}---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "\"\"\".format(fn))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------MODEL---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "#Create the DT Regression\n",
    "model = GaussianNB()\n",
    "\n",
    "#Fit the data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#Check the predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#Results\n",
    "pred_vs_act_df=pd.DataFrame({'Actual':y_test\n",
    "                             ,'PredictionClass':predictions\n",
    "                            ,'Diff':equal_index_array(l1=y_test,l2=predictions)})\n",
    "\n",
    "model_metric=model_metrics(testActualVal=y_test, predictions=predictions, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "try:\n",
    "    if imputer=='univariate':\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        X_cross = imp.fit_transform(X)\n",
    "\n",
    "\n",
    "    elif imputer=='multivariate':\n",
    "        imp=IterativeImputer(max_iter=10, random_state=14395076)\n",
    "        X_cross = imp.fit_transform(X)\n",
    "\n",
    "    elif imputer=='KNN':\n",
    "        imp = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "        X_cross = imp.fit_transform(X)\n",
    "\n",
    "    else:\n",
    "        X_cross=X\n",
    "\n",
    "    scores = cross_val_score(GaussianNB(), X_cross, y, scoring='accuracy', cv=10)\n",
    "    print(scores)\n",
    "except:\n",
    "    print(\"ERROR\")\n",
    "    pass\n",
    "print(scores)\n",
    "\n",
    "cv_rmse = scores #**0.5\n",
    "print(\"Avg Accuracy score over 5 folds: \\n\", np.mean(cv_rmse))\n",
    "print(\"Stddev Accuracy score over 5 folds: \\n\", np.std(cv_rmse))\n",
    "\n",
    "\n",
    "result_dict={}\n",
    "result_dict['Model']=model\n",
    "result_dict['Actual vs Prediction']=pred_vs_act_df\n",
    "result_dict['Accuracy']=model_metric['Accuracy']\n",
    "result_dict['Confusion']=model_metric['Confusion']\n",
    "result_dict['ClassificationRep']=model_metric['ClassificationRep']\n",
    "result_dict['CrossVal_Acc_Mean']=np.mean(cv_rmse)\n",
    "result_dict['CrossVal_Acc_STD']=np.std(cv_rmse)\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb175f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------READ IN DATA CONFIGURATION---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#Modify Here to pass in X and Y\n",
    "scaler='Standard'\n",
    "\n",
    "fn='penguins 0.2'\n",
    "fp=test_datasets[fn]['filepath']\n",
    "    \n",
    "if fn in ('penguins 0.2','penguins 0.4'):\n",
    "    df=pd.read_csv(fp,index_col=0,na_values = '?')\n",
    "else:\n",
    "    df=pd.read_csv(fp,na_values = '?')\n",
    "\n",
    "\n",
    "X=df[test_datasets[fn]['x_columns']].values\n",
    "y=df.pop(test_datasets[fn]['y_column'][0]).values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X \n",
    "                                                    ,y\n",
    "                                                    ,random_state=14395076\n",
    "                                                    ,test_size=0.33)\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------IMPUTER CONFIGURATION--------------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "imputer='multivariate'\n",
    "\n",
    "if imputer=='univariate':\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    X_train = imp.fit_transform(X_train)\n",
    "    X_test = imp.transform(X_test)\n",
    "\n",
    "\n",
    "elif imputer=='multivariate':\n",
    "    imp=IterativeImputer(max_iter=100, random_state=14395076)\n",
    "    X_train = imp.fit_transform(X_train)\n",
    "    X_test = imp.transform(X_test)\n",
    "\n",
    "elif imputer=='KNN':\n",
    "    imp = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "    X_train = imp.fit_transform(X_train)\n",
    "    X_test = imp.transform(X_test)\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------MODEL---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\"\"\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------Multi IMPUTER - {}---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "\"\"\".format(fn))\n",
    "\n",
    "\n",
    "#Create the DT Regression\n",
    "model = GaussianNB()\n",
    "\n",
    "#Fit the data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#Check the predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#Results\n",
    "pred_vs_act_df=pd.DataFrame({'Actual':y_test\n",
    "                             ,'PredictionClass':predictions\n",
    "                            ,'Diff':equal_index_array(l1=y_test,l2=predictions)})\n",
    "\n",
    "model_metric=model_metrics(testActualVal=y_test, predictions=predictions, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "try:\n",
    "    if imputer=='univariate':\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        X_cross = imp.fit_transform(X)\n",
    "\n",
    "\n",
    "    elif imputer=='multivariate':\n",
    "        imp=IterativeImputer(max_iter=10, random_state=14395076)\n",
    "        X_cross = imp.fit_transform(X)\n",
    "\n",
    "    elif imputer=='KNN':\n",
    "        imp = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "        X_cross = imp.fit_transform(X)\n",
    "\n",
    "    else:\n",
    "        X_cross=X\n",
    "\n",
    "    scores = cross_val_score(GaussianNB(), X_cross, y, scoring='accuracy', cv=10)\n",
    "    print(scores)\n",
    "except:\n",
    "    print(\"ERROR\")\n",
    "    pass\n",
    "print(scores)\n",
    "\n",
    "cv_rmse = scores #**0.5\n",
    "print(\"Avg Accuracy score over 5 folds: \\n\", np.mean(cv_rmse))\n",
    "print(\"Stddev Accuracy score over 5 folds: \\n\", np.std(cv_rmse))\n",
    "\n",
    "\n",
    "result_dict={}\n",
    "result_dict['Model']=model\n",
    "result_dict['Actual vs Prediction']=pred_vs_act_df\n",
    "result_dict['Accuracy']=model_metric['Accuracy']\n",
    "result_dict['Confusion']=model_metric['Confusion']\n",
    "result_dict['ClassificationRep']=model_metric['ClassificationRep']\n",
    "result_dict['CrossVal_Acc_Mean']=np.mean(cv_rmse)\n",
    "result_dict['CrossVal_Acc_STD']=np.std(cv_rmse)\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f77c31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------READ IN DATA CONFIGURATION---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#Modify Here to pass in X and Y\n",
    "scaler='Standard'\n",
    "\n",
    "fn='penguins 0.2'\n",
    "fp=test_datasets[fn]['filepath']\n",
    "    \n",
    "if fn in ('penguins 0.2','penguins 0.4'):\n",
    "    df=pd.read_csv(fp,index_col=0,na_values = '?')\n",
    "else:\n",
    "    df=pd.read_csv(fp,na_values = '?')\n",
    "\n",
    "\n",
    "X=df[test_datasets[fn]['x_columns']].values\n",
    "y=df.pop(test_datasets[fn]['y_column'][0]).values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X \n",
    "                                                    ,y\n",
    "                                                    ,random_state=14395076\n",
    "                                                    ,test_size=0.33)\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------IMPUTER CONFIGURATION--------------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "imputer='KNN'\n",
    "\n",
    "if imputer=='univariate':\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    X_train = imp.fit_transform(X_train)\n",
    "    X_test = imp.transform(X_test)\n",
    "\n",
    "\n",
    "elif imputer=='multivariate':\n",
    "    imp=IterativeImputer(max_iter=100, random_state=random_state)\n",
    "    X_train = imp.fit_transform(X_train)\n",
    "    X_test = imp.transform(X_test)\n",
    "\n",
    "elif imputer=='KNN':\n",
    "    imp = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "    X_train = imp.fit_transform(X_train)\n",
    "    X_test = imp.transform(X_test)\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "print(\"\"\"\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------KNN IMPUTER - {}---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "\"\"\".format(fn))\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------MODEL---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#Create the DT Regression\n",
    "model = GaussianNB()\n",
    "\n",
    "#Fit the data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#Check the predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#Results\n",
    "pred_vs_act_df=pd.DataFrame({'Actual':y_test\n",
    "                             ,'PredictionClass':predictions\n",
    "                            ,'Diff':equal_index_array(l1=y_test,l2=predictions)})\n",
    "\n",
    "model_metric=model_metrics(testActualVal=y_test, predictions=predictions, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "try:\n",
    "    if imputer=='univariate':\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        X_cross = imp.fit_transform(X)\n",
    "\n",
    "\n",
    "    elif imputer=='multivariate':\n",
    "        imp=IterativeImputer(max_iter=10, random_state=random_state)\n",
    "        X_cross = imp.fit_transform(X)\n",
    "\n",
    "    elif imputer=='KNN':\n",
    "        imp = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "        X_cross = imp.fit_transform(X)\n",
    "\n",
    "    else:\n",
    "        X_cross=X\n",
    "\n",
    "    scores = cross_val_score(GaussianNB(), X_cross, y, scoring='accuracy', cv=10)\n",
    "    print(scores)\n",
    "except:\n",
    "    print(\"ERROR\")\n",
    "    pass\n",
    "print(scores)\n",
    "\n",
    "cv_rmse = scores #**0.5\n",
    "print(\"Avg Accuracy score over 5 folds: \\n\", np.mean(cv_rmse))\n",
    "print(\"Stddev Accuracy score over 5 folds: \\n\", np.std(cv_rmse))\n",
    "\n",
    "\n",
    "result_dict={}\n",
    "result_dict['Model']=model\n",
    "result_dict['Actual vs Prediction']=pred_vs_act_df\n",
    "result_dict['Accuracy']=model_metric['Accuracy']\n",
    "result_dict['Confusion']=model_metric['Confusion']\n",
    "result_dict['ClassificationRep']=model_metric['ClassificationRep']\n",
    "result_dict['CrossVal_Acc_Mean']=np.mean(cv_rmse)\n",
    "result_dict['CrossVal_Acc_STD']=np.std(cv_rmse)\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a26b25d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Penguins 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee17835",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------READ IN DATA CONFIGURATION---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "#Modify Here to pass in X and Y\n",
    "scaler='Standard'\n",
    "\n",
    "fn='penguins 0.4'\n",
    "fp=test_datasets[fn]['filepath']\n",
    "    \n",
    "if fn in ('penguins 0.2','penguins 0.4'):\n",
    "    df=pd.read_csv(fp,index_col=0,na_values = '?')\n",
    "else:\n",
    "    df=pd.read_csv(fp,na_values = '?')\n",
    "\n",
    "\n",
    "X=df[test_datasets[fn]['x_columns']].values\n",
    "y=df.pop(test_datasets[fn]['y_column'][0]).values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X \n",
    "                                                    ,y\n",
    "                                                    ,random_state=14395076\n",
    "                                                    ,test_size=0.33)\n",
    "\n",
    "if scaler=='Standard':\n",
    "    scaler = StandardScaler()\n",
    "elif scaler=='MinMax':    \n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------MODEL---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "print(\"\"\"\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------MINE - {}---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "\"\"\".format(fn))\n",
    "\n",
    "#Create the DT Regression\n",
    "model = MyGaussianNB()\n",
    "\n",
    "#Fit the data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#Check the predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#Results\n",
    "pred_vs_act_df=pd.DataFrame({'Actual':y_test\n",
    "                             ,'PredictionClass':predictions\n",
    "                            ,'Diff':equal_index_array(l1=y_test,l2=predictions)})\n",
    "\n",
    "model_metric=model_metrics(testActualVal=y_test, predictions=predictions, verbose=True)\n",
    "\n",
    "\n",
    "scores = cross_val_score(MyGaussianNB(), X, y, scoring='accuracy', cv=10)\n",
    "print(scores)\n",
    "\n",
    "cv_rmse = scores #**0.5\n",
    "print(\"Avg Accuracy score over 5 folds: \\n\", np.mean(cv_rmse))\n",
    "print(\"Stddev Accuracy score over 5 folds: \\n\", np.std(cv_rmse))\n",
    "\n",
    "\n",
    "result_dict={}\n",
    "result_dict['Model']=model\n",
    "result_dict['Actual vs Prediction']=pred_vs_act_df\n",
    "result_dict['Accuracy']=model_metric['Accuracy']\n",
    "result_dict['Confusion']=model_metric['Confusion']\n",
    "result_dict['ClassificationRep']=model_metric['ClassificationRep']\n",
    "result_dict['CrossVal_Acc_Mean']=np.mean(cv_rmse)\n",
    "result_dict['CrossVal_Acc_STD']=np.std(cv_rmse)\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbcc62f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "2. Run this bit to test on SK Learns' GaussianNaiveBayes without imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96608a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################################\n",
    "\n",
    "    #-------------READ IN DATA CONFIGURATION---------------------#\n",
    "\n",
    "    ##############################################################\n",
    "    \n",
    "\n",
    "    #Modify Here to pass in X and Y\n",
    "    scaler='Standard'\n",
    "\n",
    "    fn='penguins 0.4'\n",
    "    fp=test_datasets[fn]['filepath']\n",
    "\n",
    "    if fn in ('penguins 0.2','penguins 0.4'):\n",
    "        df=pd.read_csv(fp,index_col=0,na_values = '?')\n",
    "    else:\n",
    "        df=pd.read_csv(fp,na_values = '?')\n",
    "\n",
    "\n",
    "    X=df[test_datasets[fn]['x_columns']].values\n",
    "    y=df.pop(test_datasets[fn]['y_column'][0]).values\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X \n",
    "                                                        ,y\n",
    "                                                        ,random_state=14395076\n",
    "                                                        ,test_size=0.33)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"\"\"\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------NO IMPUTER - {}---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "\"\"\".format(fn))\n",
    "\n",
    "    ##############################################################\n",
    "\n",
    "    #-------------MODEL---------------------#\n",
    "\n",
    "    ##############################################################\n",
    "\n",
    "    #Create the DT Regression\n",
    "    model = GaussianNB()\n",
    "\n",
    "    #Fit the data\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "    #Check the predictions\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    #Results\n",
    "    pred_vs_act_df=pd.DataFrame({'Actual':y_test\n",
    "                                 ,'PredictionClass':predictions\n",
    "                                ,'Diff':equal_index_array(l1=y_test,l2=predictions)})\n",
    "\n",
    "    model_metric=model_metrics(testActualVal=y_test, predictions=predictions, verbose=True)\n",
    "\n",
    "\n",
    "    scores = cross_val_score(MyGaussianNB(), X, y, scoring='accuracy', cv=10)\n",
    "    print(scores)\n",
    "\n",
    "    cv_rmse = scores #**0.5\n",
    "    print(\"Avg Accuracy score over 5 folds: \\n\", np.mean(cv_rmse))\n",
    "    print(\"Stddev Accuracy score over 5 folds: \\n\", np.std(cv_rmse))\n",
    "\n",
    "\n",
    "    result_dict={}\n",
    "    result_dict['Model']=model\n",
    "    result_dict['Actual vs Prediction']=pred_vs_act_df\n",
    "    result_dict['Accuracy']=model_metric['Accuracy']\n",
    "    result_dict['Confusion']=model_metric['Confusion']\n",
    "    result_dict['ClassificationRep']=model_metric['ClassificationRep']\n",
    "    result_dict['CrossVal_Acc_Mean']=np.mean(cv_rmse)\n",
    "    result_dict['CrossVal_Acc_STD']=np.std(cv_rmse)\n",
    "    result_dict\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Default SKLearn won't accept NAN - {}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538de06",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "3. Run this bit to test on SK Learns' GaussianNaiveBayes with imputation of the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bfda4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------READ IN DATA CONFIGURATION---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "#Modify Here to pass in X and Y\n",
    "scaler='Standard'\n",
    "\n",
    "fn='penguins 0.4'\n",
    "fp=test_datasets[fn]['filepath']\n",
    "    \n",
    "if fn in ('penguins 0.2','penguins 0.4'):\n",
    "    df=pd.read_csv(fp,index_col=0,na_values = '?')\n",
    "else:\n",
    "    df=pd.read_csv(fp,na_values = '?')\n",
    "\n",
    "\n",
    "X=df[test_datasets[fn]['x_columns']].values\n",
    "y=df.pop(test_datasets[fn]['y_column'][0]).values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X \n",
    "                                                    ,y\n",
    "                                                    ,random_state=14395076\n",
    "                                                    ,test_size=0.33)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X \n",
    "                                                    ,y\n",
    "                                                    ,random_state=14395076\n",
    "                                                    ,test_size=0.33)\n",
    "\n",
    "if scaler=='Standard':\n",
    "    scaler = StandardScaler()\n",
    "elif scaler=='MinMax':    \n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------IMPUTER CONFIGURATION--------------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "imputer='univariate'\n",
    "\n",
    "if imputer=='univariate':\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    X_train = imp.fit_transform(X_train)\n",
    "    X_test = imp.transform(X_test)\n",
    "\n",
    "\n",
    "elif imputer=='multivariate':\n",
    "    imp=IterativeImputer(max_iter=100, random_state=14395076)\n",
    "    X_train = imp.fit_transform(X_train)\n",
    "    X_test = imp.transform(X_test)\n",
    "\n",
    "elif imputer=='KNN':\n",
    "    imp = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "    X_train = imp.fit_transform(X_train)\n",
    "    X_test = imp.transform(X_test)\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\"\"\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------UNI IMPUTER - {}---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "\"\"\".format(fn))\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------MODEL---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "#Create the DT Regression\n",
    "model = GaussianNB()\n",
    "\n",
    "#Fit the data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#Check the predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#Results\n",
    "pred_vs_act_df=pd.DataFrame({'Actual':y_test\n",
    "                             ,'PredictionClass':predictions\n",
    "                            ,'Diff':equal_index_array(l1=y_test,l2=predictions)})\n",
    "\n",
    "model_metric=model_metrics(testActualVal=y_test, predictions=predictions, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "try:\n",
    "    if imputer=='univariate':\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        X_cross = imp.fit_transform(X)\n",
    "\n",
    "\n",
    "    elif imputer=='multivariate':\n",
    "        imp=IterativeImputer(max_iter=10, random_state=14395076)\n",
    "        X_cross = imp.fit_transform(X)\n",
    "\n",
    "    elif imputer=='KNN':\n",
    "        imp = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "        X_cross = imp.fit_transform(X)\n",
    "\n",
    "    else:\n",
    "        X_cross=X\n",
    "\n",
    "    scores = cross_val_score(GaussianNB(), X_cross, y, scoring='accuracy', cv=10)\n",
    "    print(scores)\n",
    "except:\n",
    "    print(\"ERROR\")\n",
    "    pass\n",
    "print(scores)\n",
    "\n",
    "cv_rmse = scores #**0.5\n",
    "print(\"Avg Accuracy score over 5 folds: \\n\", np.mean(cv_rmse))\n",
    "print(\"Stddev Accuracy score over 5 folds: \\n\", np.std(cv_rmse))\n",
    "\n",
    "\n",
    "result_dict={}\n",
    "result_dict['Model']=model\n",
    "result_dict['Actual vs Prediction']=pred_vs_act_df\n",
    "result_dict['Accuracy']=model_metric['Accuracy']\n",
    "result_dict['Confusion']=model_metric['Confusion']\n",
    "result_dict['ClassificationRep']=model_metric['ClassificationRep']\n",
    "result_dict['CrossVal_Acc_Mean']=np.mean(cv_rmse)\n",
    "result_dict['CrossVal_Acc_STD']=np.std(cv_rmse)\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9a433f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "4. Run this bit to test on SK Learns' GaussianNaiveBayes with iterative imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf719aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------READ IN DATA CONFIGURATION---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#Modify Here to pass in X and Y\n",
    "scaler='Standard'\n",
    "\n",
    "fn='penguins 0.4'\n",
    "fp=test_datasets[fn]['filepath']\n",
    "    \n",
    "if fn in ('penguins 0.2','penguins 0.4'):\n",
    "    df=pd.read_csv(fp,index_col=0,na_values = '?')\n",
    "else:\n",
    "    df=pd.read_csv(fp,na_values = '?')\n",
    "\n",
    "\n",
    "X=df[test_datasets[fn]['x_columns']].values\n",
    "y=df.pop(test_datasets[fn]['y_column'][0]).values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X \n",
    "                                                    ,y\n",
    "                                                    ,random_state=14395076\n",
    "                                                    ,test_size=0.33)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\"\"\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------MULTI IMPUTER - {}---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "\"\"\".format(fn))\n",
    "##############################################################\n",
    "\n",
    "#-------------IMPUTER CONFIGURATION--------------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "imputer='multivariate'\n",
    "\n",
    "if imputer=='univariate':\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    X_train = imp.fit_transform(X_train)\n",
    "    X_test = imp.transform(X_test)\n",
    "\n",
    "\n",
    "elif imputer=='multivariate':\n",
    "    imp=IterativeImputer(max_iter=100, random_state=14395076)\n",
    "    X_train = imp.fit_transform(X_train)\n",
    "    X_test = imp.transform(X_test)\n",
    "\n",
    "elif imputer=='KNN':\n",
    "    imp = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "    X_train = imp.fit_transform(X_train)\n",
    "    X_test = imp.transform(X_test)\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------MODEL---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#Create the DT Regression\n",
    "model = GaussianNB()\n",
    "\n",
    "#Fit the data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#Check the predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#Results\n",
    "pred_vs_act_df=pd.DataFrame({'Actual':y_test\n",
    "                             ,'PredictionClass':predictions\n",
    "                            ,'Diff':equal_index_array(l1=y_test,l2=predictions)})\n",
    "\n",
    "model_metric=model_metrics(testActualVal=y_test, predictions=predictions, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "try:\n",
    "    if imputer=='univariate':\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        X_cross = imp.fit_transform(X)\n",
    "\n",
    "\n",
    "    elif imputer=='multivariate':\n",
    "        imp=IterativeImputer(max_iter=10, random_state=14395076)\n",
    "        X_cross = imp.fit_transform(X)\n",
    "\n",
    "    elif imputer=='KNN':\n",
    "        imp = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "        X_cross = imp.fit_transform(X)\n",
    "\n",
    "    else:\n",
    "        X_cross=X\n",
    "\n",
    "    scores = cross_val_score(GaussianNB(), X_cross, y, scoring='accuracy', cv=10)\n",
    "    print(scores)\n",
    "except:\n",
    "    print(\"ERROR\")\n",
    "    pass\n",
    "print(scores)\n",
    "\n",
    "cv_rmse = scores #**0.5\n",
    "print(\"Avg Accuracy score over 5 folds: \\n\", np.mean(cv_rmse))\n",
    "print(\"Stddev Accuracy score over 5 folds: \\n\", np.std(cv_rmse))\n",
    "\n",
    "\n",
    "result_dict={}\n",
    "result_dict['Model']=model\n",
    "result_dict['Actual vs Prediction']=pred_vs_act_df\n",
    "result_dict['Accuracy']=model_metric['Accuracy']\n",
    "result_dict['Confusion']=model_metric['Confusion']\n",
    "result_dict['ClassificationRep']=model_metric['ClassificationRep']\n",
    "result_dict['CrossVal_Acc_Mean']=np.mean(cv_rmse)\n",
    "result_dict['CrossVal_Acc_STD']=np.std(cv_rmse)\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7f0a4b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "5. Run this bit to test on SK Learns' GaussianNaiveBayes with KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a5988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------READ IN DATA CONFIGURATION---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#Modify Here to pass in X and Y\n",
    "scaler='Standard'\n",
    "\n",
    "fn='penguins 0.4'\n",
    "fp=test_datasets[fn]['filepath']\n",
    "    \n",
    "if fn in ('penguins 0.2','penguins 0.4'):\n",
    "    df=pd.read_csv(fp,index_col=0,na_values = '?')\n",
    "else:\n",
    "    df=pd.read_csv(fp,na_values = '?')\n",
    "\n",
    "\n",
    "X=df[test_datasets[fn]['x_columns']].values\n",
    "y=df.pop(test_datasets[fn]['y_column'][0]).values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X \n",
    "                                                    ,y\n",
    "                                                    ,random_state=14395076\n",
    "                                                    ,test_size=0.33)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\"\"\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------KNN IMPUTER - {}---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "\"\"\".format(fn))\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------IMPUTER CONFIGURATION--------------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "imputer='KNN'\n",
    "\n",
    "if imputer=='univariate':\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    X_train = imp.fit_transform(X_train)\n",
    "    X_test = imp.transform(X_test)\n",
    "\n",
    "\n",
    "elif imputer=='multivariate':\n",
    "    imp=IterativeImputer(max_iter=100, random_state=random_state)\n",
    "    X_train = imp.fit_transform(X_train)\n",
    "    X_test = imp.transform(X_test)\n",
    "\n",
    "elif imputer=='KNN':\n",
    "    imp = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "    X_train = imp.fit_transform(X_train)\n",
    "    X_test = imp.transform(X_test)\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#-------------MODEL---------------------#\n",
    "\n",
    "##############################################################\n",
    "\n",
    "#Create the DT Regression\n",
    "model = GaussianNB()\n",
    "\n",
    "#Fit the data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#Check the predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#Results\n",
    "pred_vs_act_df=pd.DataFrame({'Actual':y_test\n",
    "                             ,'PredictionClass':predictions\n",
    "                            ,'Diff':equal_index_array(l1=y_test,l2=predictions)})\n",
    "\n",
    "model_metric=model_metrics(testActualVal=y_test, predictions=predictions, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "try:\n",
    "    if imputer=='univariate':\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        X_cross = imp.fit_transform(X)\n",
    "\n",
    "\n",
    "    elif imputer=='multivariate':\n",
    "        imp=IterativeImputer(max_iter=10, random_state=random_state)\n",
    "        X_cross = imp.fit_transform(X)\n",
    "\n",
    "    elif imputer=='KNN':\n",
    "        imp = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "        X_cross = imp.fit_transform(X)\n",
    "\n",
    "    else:\n",
    "        X_cross=X\n",
    "\n",
    "    scores = cross_val_score(GaussianNB(), X_cross, y, scoring='accuracy', cv=10)\n",
    "    print(scores)\n",
    "except:\n",
    "    print(\"ERROR\")\n",
    "    pass\n",
    "print(scores)\n",
    "\n",
    "cv_rmse = scores #**0.5\n",
    "print(\"Avg Accuracy score over 5 folds: \\n\", np.mean(cv_rmse))\n",
    "print(\"Stddev Accuracy score over 5 folds: \\n\", np.std(cv_rmse))\n",
    "\n",
    "\n",
    "result_dict={}\n",
    "result_dict['Model']=model\n",
    "result_dict['Actual vs Prediction']=pred_vs_act_df\n",
    "result_dict['Accuracy']=model_metric['Accuracy']\n",
    "result_dict['Confusion']=model_metric['Confusion']\n",
    "result_dict['ClassificationRep']=model_metric['ClassificationRep']\n",
    "result_dict['CrossVal_Acc_Mean']=np.mean(cv_rmse)\n",
    "result_dict['CrossVal_Acc_STD']=np.std(cv_rmse)\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7738f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c9628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098351b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6924ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee567c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
